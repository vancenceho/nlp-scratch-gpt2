{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vancenceho/kaopei-nlp-gpt2/blob/extended-task/qwen_gpt2_with_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pmLDoL2a5Fi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "470037fa-3732-4bac-ac54-a9d772b99a7f"
      },
      "id": "pmLDoL2a5Fi_",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/kp-gpt2-nlp\")\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "UUn58poR5Cue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a805c4a5-e70c-4aa4-e8af-29e50a91ed88"
      },
      "id": "UUn58poR5Cue",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/kp-gpt2-nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "96361c6c",
      "metadata": {
        "id": "96361c6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c85d5cf-b540-4be9-fecb-896932f99aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDependencies installed successfully.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q -r requirements_colab.txt\n",
        "print(\"Dependencies installed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a2903822",
      "metadata": {
        "id": "a2903822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688c9e1b-9abf-4c82-db3a-f127562782b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, dtype\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Optimizer\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "from config import PretrainedConfig, GPT2Config\n",
        "from transformers import GPT2Model as OpenAIGPT2Model\n",
        "from transformers import GPT2Tokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from utils import *\n",
        "from einops import rearrange\n",
        "from typing import Callable, Iterable, Tuple\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23384a93",
      "metadata": {
        "id": "23384a93"
      },
      "source": [
        "# Task 1: Implement GPT-2\n",
        "In this task, you will:\n",
        "- Load the GPT-2 tokenizer.\n",
        "- Implement the GPT-2 model.\n",
        "- Implement the Adam optimizer.\n",
        "- Conduct a toy pretraining of GPT-2 on the provided small dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e498552",
      "metadata": {
        "id": "6e498552"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb30c57",
      "metadata": {
        "id": "5eb30c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509,
          "referenced_widgets": [
            "97219667bb9846d68df0451427c6beca",
            "c94e5271748a46eda10e107ce42e916c",
            "70a53f778ab04ee1b7236d93786c65bf",
            "27388a6abcf44262b7b3e945f2d6534c",
            "ec68dc4fd0fd4841860d7f31c2979872",
            "fabb95a87b2e4ebca96bf8498a485441",
            "4058baf34b0b429eb5f0dce78becda41",
            "30d5fd812213455ea3a720c060ade310",
            "81e4146cce5a4aff9591af846df9217f",
            "59ea86727678451cacaa664b97db08a8",
            "695857dcf9ca4c8a9550111d97ada250",
            "0173166a0b85412db9f6c8d5a12ad45d",
            "9ce935d2c2a646d9869ede8a53d9a0b2",
            "61c5e5fdbed947e384c775756ba7969d",
            "4fe76772b0ff4cfcb5494e2a6aeb44f0",
            "87ee0a80977c40859cd87fa774a9043f",
            "bdb4bb743d264c1b8d5d0859af520ba1",
            "f2cd2a25acb6427dbbdaab68dd5ebf4e",
            "44e8b6aa514d45429a13341d3faf174f",
            "37e7e6da19ad4abcbd4394c13c9111ad",
            "54221a4bc855477a98d1dcc61f81a76e",
            "b0f2807e599e4cf085d4b4ef8c77e0a8",
            "c5a3a31f803a481399970c8e557dac20",
            "2bb9140b6c4d468ea609eed8b2452565",
            "9ef1ac88c1a5444d871c79fc48e5759b",
            "bce9ce866dfe40d2b6764aba1a5689b1",
            "02be77a380b24aaeb7df8e9667231a22",
            "776ffe626f6a4280a4a23e89dc474193",
            "216962566e0f4795aad21b8397bd2539",
            "1db5b58687434bb68de7acad3478cdf4",
            "74f446d177a644208b725b59f085a3fa",
            "ff4e258a755c429c939d4927e1fbbf2b",
            "347ee5f33ccb4d708f258a06d9a17df6",
            "fd67dcfb363b4dd3b376897817ef3485",
            "38cedb1b3a78445086b5a80f0fc6f080",
            "4ffce14b5b264e749f83227f1cb5f508",
            "000a1228d4e74672835301761252c2ec",
            "dc9f669b66524368a7917757adb605cc",
            "25744974de2d4f13a98e11371a87b568",
            "58383d31d54040748cb0d56e229a0ccf",
            "59276f586f21496fadd259345b4c85bd",
            "53019c62e7e64f48b5b487b1eec8e67a",
            "c1f360ee61e04530b627f06357e7679b",
            "bb2e120f73464dfba5fb1c60bc6a516c",
            "b281671ab51b4ecfaa46a6748d0a345c",
            "5ddf01ea2287428f9d79b06a0addce3d",
            "cd4b82b64787432f8fec09c35fc56439",
            "1c444bd674884991b0965e35768e79dd",
            "a13b1344e7fa43bd91297fea2f2ca060",
            "86015e175ff94427954673c82800eeb3",
            "dd7767ac609643bd84f40c044a2895ca",
            "2a8747ed682544c7943e3ebca7788fee",
            "90c117aabc324d378d43be91c926c90b",
            "1f68c36329894c5fbc3ce091bc87fd42",
            "59450c1d1fec44d58f1e62a42e54e881"
          ]
        },
        "outputId": "3545e231-1a0c-4503-cfac-a5a807ec5d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97219667bb9846d68df0451427c6beca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0173166a0b85412db9f6c8d5a12ad45d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5a3a31f803a481399970c8e557dac20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd67dcfb363b4dd3b376897817ef3485"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b281671ab51b4ecfaa46a6748d0a345c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [14618, 11, 428, 318, 262, 3726, 286, 4277, 2457, 1628, 0]\n",
            "token Welcome\n",
            "token ,\n",
            "token  this\n",
            "token  is\n",
            "token  the\n",
            "token  beginning\n",
            "token  of\n",
            "token  default\n",
            "token  final\n",
            "token  project\n",
            "token !\n"
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "text = \"Welcome, this is the beginning of default final project!\"\n",
        "input_ids = tokenizer(text)['input_ids']\n",
        "print('input_ids:', input_ids)\n",
        "for token in input_ids:\n",
        "    print('token', tokenizer.decode(token))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bd74b99",
      "metadata": {
        "id": "0bd74b99"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "061db6ef",
      "metadata": {
        "id": "061db6ef"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_attention_heads = config.num_attention_heads\n",
        "    self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
        "    self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
        "\n",
        "    # Initialize the linear transformation layers for key, value, query.\n",
        "    self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "    self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "    self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
        "    # This dropout is applied to normalized attention scores following the original\n",
        "    # implementation of transformer. Although it is a bit unusual, we empirically\n",
        "    # observe that it yields better performance.\n",
        "    self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "  def transform(self, x, linear_layer):\n",
        "    # The corresponding linear_layer of k, v, q are used to project the hidden_state (x).\n",
        "    proj = linear_layer(x)\n",
        "    # Next, we need to produce multiple heads for the proj. This is done by spliting the\n",
        "    # hidden state to self.num_attention_heads, each of size self.attention_head_size.\n",
        "    proj = rearrange(proj, 'b t (h d) -> b t h d', h=self.num_attention_heads)\n",
        "    # By proper transpose, we have proj of size [bs, num_attention_heads, seq_len, attention_head_size].\n",
        "    proj = rearrange(proj, 'b t h d -> b h t d')\n",
        "    return proj\n",
        "\n",
        "  def attention(self, key, query, value, attention_mask):\n",
        "    \"\"\"\n",
        "    TODO-1: Compute scaled dot-product attention for GPT-2.\n",
        "\n",
        "    Implementation hints:\n",
        "    1. Compute raw attention scores using QK^T, and scale them by sqrt(d_k).\n",
        "    2. Apply a causal mask (lower-triangular) to prevent attending to future tokens.\n",
        "    3. Optionally add the external attention_mask (e.g., padding positions).\n",
        "    4. Normalize the scores with softmax to obtain attention probabilities.\n",
        "    5. Apply dropout on the probabilities.\n",
        "    6. Use them to weight the values (V) and obtain the context vectors.\n",
        "    7. Finally, merge all attention heads back into a single hidden representation.\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # Compute raw attention scores using QK^T, and scale them by sqrt(d_k).\n",
        "    # q, k, v shapes: [B, H, T, d]\n",
        "    raw_scores = torch.matmul(query, key.transpose(-2, -1))  # [B, H, T, T]\n",
        "    d_k = query.size(-1)\n",
        "    scaled_scores = raw_scores / (torch.sqrt(torch.tensor(d_k, dtype=torch.float32)))\n",
        "\n",
        "    # Apply a causal mask over the token dimension (lower triangular over T x T).\n",
        "    Tq = query.size(-2)\n",
        "    Tk = key.size(-2)\n",
        "    causal = torch.tril(torch.ones((Tq, Tk), device=query.device, dtype=torch.bool))  # [Tq, Tk]; 1 for keep, 0 for mask; create a lower triangular mask\n",
        "    scaled_scores = scaled_scores.masked_fill(~causal, torch.finfo(scaled_scores.dtype).min)  # Fill masked positions with -inf\n",
        "\n",
        "    # Optionally add the external attention_mask (e.g., padding positions).\n",
        "    if attention_mask is not None:\n",
        "        # attention_mask is already in logit space: 0 for keep, large negative for mask\n",
        "        scaled_scores = scaled_scores + attention_mask\n",
        "\n",
        "    # Normalize the scores with softmax to obtain attention probabilities.\n",
        "    attention_probs = F.softmax(scaled_scores, dim=-1)\n",
        "\n",
        "    # Apply dropout to the probabilities.\n",
        "    attention_probs = self.dropout(attention_probs)\n",
        "\n",
        "    # Weight the values (V) and obtain the context vectors.\n",
        "    context_vectors = torch.matmul(attention_probs, value)  # [B, H, T, d]\n",
        "\n",
        "    # Merge all attention heads back into a single hidden representation.\n",
        "    context_vectors = rearrange(context_vectors, 'b h t d -> b t (h d)')\n",
        "\n",
        "    return context_vectors\n",
        "\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask):\n",
        "    \"\"\"\n",
        "    hidden_states: [bs, seq_len, hidden_state]\n",
        "    attention_mask: [bs, 1, 1, seq_len]\n",
        "    output: [bs, seq_len, hidden_state]\n",
        "    \"\"\"\n",
        "    # First, we have to generate the key, value, query for each token for multi-head attention\n",
        "    # using self.transform (more details inside the function).\n",
        "    # Size of *_layer is [bs, num_attention_heads, seq_len, attention_head_size].\n",
        "    key_layer = self.transform(hidden_states, self.key)\n",
        "    value_layer = self.transform(hidden_states, self.value)\n",
        "    query_layer = self.transform(hidden_states, self.query)\n",
        "\n",
        "    # Calculate the multi-head attention using the self.attention function.\n",
        "    attn_value = self.attention(key_layer, query_layer, value_layer, attention_mask)\n",
        "    return attn_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "efc9ad59",
      "metadata": {
        "id": "efc9ad59"
      },
      "outputs": [],
      "source": [
        "class GPT2Layer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    # Multi-head attention.\n",
        "    self.self_attention = CausalSelfAttention(config)\n",
        "    # Add-norm for multi-head attention.\n",
        "    self.attention_dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.attention_layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "    self.attention_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    # Feed forward.\n",
        "    self.interm_dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "    self.interm_af = F.gelu\n",
        "    # Add-norm for feed forward.\n",
        "    self.out_dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "    self.out_layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "    self.out_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def add(self, input, output, dense_layer, dropout):\n",
        "    \"\"\"\n",
        "    TODO-2: Residual connection with dense projection and dropout.\n",
        "\n",
        "    Implementation hints:\n",
        "    1. Project the 'output' through dense_layer.\n",
        "    2. Apply dropout to prevent overfitting.\n",
        "    3. Add the original 'input' (residual connection) to the processed output.\n",
        "    \"\"\"\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # Apply dense projection to the output.\n",
        "    output = dense_layer(output)\n",
        "\n",
        "    # Apply dropout to prevent overfitting.\n",
        "    output = dropout(output)\n",
        "\n",
        "    # Add original 'input' (residual connection) to the processed output.\n",
        "    output = input + output\n",
        "\n",
        "    return output\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask):\n",
        "    \"\"\"\n",
        "    TODO-3: Forward pass of a GPT-2 layer.\n",
        "\n",
        "    Implementation hints:\n",
        "    ---- Self-Attention Block ----\n",
        "    1. LayerNorm the input for stability using self.attention_layer_norm.\n",
        "    2. Compute multi-head causal self-attention using self.self_attention.\n",
        "    3. Apply residual connection using self.add (dense_layer=self.attention_dense, dropout=self.attention_dropout).\n",
        "\n",
        "    ---- Feed Forward Block ----\n",
        "    4. LayerNorm the hidden_states from attention block using self.out_layer_norm.\n",
        "    5. Pass through a two-layer feed-forward network with activation:\n",
        "       self.interm_dense -> self.interm_af -> self.out_dense\n",
        "    6. Apply residual connection again using self.add (dense_layer=self.out_dense, dropout=self.out_dropout).\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # ---- Self-Attention Block (Pre-LN) ----\n",
        "    residual = hidden_states\n",
        "    # LayerNorm the input for stability using self.attention_layer_norm.\n",
        "    normed = self.attention_layer_norm(hidden_states)\n",
        "    # Compute multi-head causal self-attention using self.self_attention.\n",
        "    attention_output = self.self_attention(normed, attention_mask)\n",
        "    # Apply residual connection using self.add (dense_layer=self.attention_dense, dropout=self.attention_dropout).\n",
        "    hidden_states = self.add(residual, attention_output, self.attention_dense, self.attention_dropout)\n",
        "\n",
        "    # ---- Feed Forward Block (Pre-LN) ----\n",
        "    residual = hidden_states\n",
        "    # LayerNorm the hidden_states from attention block using self.out_layer_norm.\n",
        "    normed = self.out_layer_norm(hidden_states)\n",
        "    # Pass through a two-layer feed-forward network with activation: self.interm_dense -> self.interm_af -> self.out_dense\n",
        "    ffn_preproj = self.interm_dense(normed)\n",
        "    ffn_preproj = self.interm_af(ffn_preproj)\n",
        "    # Apply residual connection again using self.add (dense_layer=self.out_dense, dropout=self.out_dropout).\n",
        "    hidden_states = self.add(residual, ffn_preproj, self.out_dense, self.out_dropout)\n",
        "\n",
        "    return hidden_states\n",
        "\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "70a04146",
      "metadata": {
        "id": "70a04146"
      },
      "outputs": [],
      "source": [
        "class GPTPreTrainedModel(nn.Module):\n",
        "\n",
        "  def __init__(self, config: PretrainedConfig, *inputs, **kwargs):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.name_or_path = config.name_or_path\n",
        "\n",
        "  def init_weights(self):\n",
        "    # Initialize weights\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\" Initialize the weights \"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "      # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "      module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @property\n",
        "  def dtype(self) -> dtype:\n",
        "    return get_parameter_dtype(self)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e68d1cd2",
      "metadata": {
        "id": "e68d1cd2"
      },
      "outputs": [],
      "source": [
        "class GPT2Model(GPTPreTrainedModel):\n",
        "  \"\"\"\n",
        "  The GPT model returns the final embeddings for each token in a sentence.\n",
        "\n",
        "  The model consists of:\n",
        "  1. Embedding layers (used in self.embed).\n",
        "  2. A stack of n GPT layers (used in self.encode).\n",
        "  3. A linear transformation layer for the [CLS] token (used in self.forward, as given).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "    self.config = config\n",
        "\n",
        "    # Embedding layers.\n",
        "    self.word_embedding = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
        "    self.pos_embedding = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "    self.embed_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    # Register position_ids (1, len position emb) to buffer because it is a constant.\n",
        "    position_ids = torch.arange(config.max_position_embeddings).unsqueeze(0)\n",
        "    self.register_buffer('position_ids', position_ids)\n",
        "\n",
        "    # GPT-2 layers.\n",
        "    self.gpt_layers = nn.ModuleList([GPT2Layer(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    # [CLS] token transformations.\n",
        "    self.pooler_dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.pooler_af = nn.Tanh()\n",
        "\n",
        "    # Final layer norm.\n",
        "    self.final_layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
        "\n",
        "    self.init_weights()\n",
        "\n",
        "  def embed(self, input_ids):\n",
        "    \"\"\"\n",
        "    TODO-4: Embedding layer of the GPT-2 model.\n",
        "\n",
        "    Implementation hints:\n",
        "    1. Use self.word_embedding to convert input_ids to embeddings.\n",
        "    2. Generate position ids and convert to embeddings using self.pos_embedding.\n",
        "    3. Sum token and position embeddings.\n",
        "    4. Apply self.embed_dropout to the sum.\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # Use self.word_embedding to convert input_ids to embeddings.\n",
        "    embeddings = self.word_embedding(input_ids)\n",
        "\n",
        "    # Generate position ids and convert to embeddings using self.pos_embedding.\n",
        "    position_ids = self.position_ids[:, :input_ids.shape[1]]\n",
        "    position_embeddings = self.pos_embedding(position_ids)\n",
        "\n",
        "    # Sum token and position embeddings.\n",
        "    embeddings = embeddings + position_embeddings\n",
        "\n",
        "    # Apply self.embed_dropout to the sum.\n",
        "    embeddings = self.embed_dropout(embeddings)\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "  def encode(self, hidden_states, attention_mask):\n",
        "    \"\"\"\n",
        "    hidden_states: the output from the embedding layer [batch_size, seq_len, hidden_size]\n",
        "    attention_mask: [batch_size, seq_len]\n",
        "    \"\"\"\n",
        "    # Get the extended attention mask for self-attention.\n",
        "    # Returns extended_attention_mask of size [batch_size, 1, 1, seq_len].\n",
        "    # Distinguishes between non-padding tokens (with a value of 0) and padding tokens\n",
        "    # (with a value of a large negative number).\n",
        "    extended_attention_mask: torch.Tensor = get_extended_attention_mask(attention_mask, self.dtype)\n",
        "\n",
        "    # Pass the hidden states through the encoder layers.\n",
        "    for i, layer_module in enumerate(self.gpt_layers):\n",
        "      # Feed the encoding from the last bert_layer to the next.\n",
        "      hidden_states = layer_module(hidden_states, extended_attention_mask)\n",
        "\n",
        "    return hidden_states\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    \"\"\"\n",
        "    input_ids: [batch_size, seq_len], seq_len is the max length of the batch\n",
        "    attention_mask: same size as input_ids, 1 represents non-padding tokens, 0 represents padding tokens\n",
        "    \"\"\"\n",
        "    # Get the embedding for each input token.\n",
        "    embedding_output = self.embed(input_ids=input_ids)\n",
        "\n",
        "    # Feed to a transformer (a stack of GPTLayers).\n",
        "    sequence_output = self.encode(embedding_output, attention_mask=attention_mask)\n",
        "    sequence_output = self.final_layer_norm(sequence_output)\n",
        "\n",
        "    # Get the hidden state of the final token.\n",
        "    last_non_pad_idx = attention_mask.sum(dim=1) - 1  # Subtract 1 to get last index\n",
        "    last_token = sequence_output[torch.arange(sequence_output.shape[0]), last_non_pad_idx]\n",
        "\n",
        "    return {'last_hidden_state': sequence_output, 'last_token': last_token}\n",
        "\n",
        "  def hidden_state_to_token(self, hidden_state):\n",
        "    \"\"\"\n",
        "    TODO-5: Convert hidden states back to token logits.\n",
        "\n",
        "    Implementation hints:\n",
        "    - GPT-2 uses weight tying with the input word embeddings.\n",
        "    - The logits are the dot product between output hidden states and the word embedding weights: hidden_state(s) * E^T\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # Compute the dot product between the hidden states and the word embedding weights: hidden_state(s) * E^T\n",
        "    logits = torch.matmul(hidden_state, self.word_embedding.weight.T)\n",
        "\n",
        "    return logits\n",
        "\n",
        "    raise NotImplementedError\n",
        "\n",
        "  @classmethod\n",
        "  def from_pretrained(cls, model='gpt2', d=768, l=12, num_heads=12):\n",
        "    gpt_model = OpenAIGPT2Model.from_pretrained(model).eval()\n",
        "    our_model = GPT2Model(GPT2Config(hidden_size=d, num_hidden_layers=l,num_attention_heads=num_heads,\n",
        "                                     intermediate_size=d*3)).eval()\n",
        "\n",
        "    # Load word and positional embeddings.\n",
        "    our_model.word_embedding.load_state_dict(gpt_model.wte.state_dict())\n",
        "    our_model.pos_embedding.load_state_dict(gpt_model.wpe.state_dict())\n",
        "\n",
        "    for i in range(l):\n",
        "      l = our_model.gpt_layers[i]\n",
        "      # Remap the Q,K,V weights from a conv1d to 3 linear projections\n",
        "      l.self_attention.query.weight.data = gpt_model.state_dict()[f'h.{i}.attn.c_attn.weight'][:, :d].T\n",
        "      l.self_attention.query.bias.data = gpt_model.state_dict()[f'h.{i}.attn.c_attn.bias'][:d]\n",
        "      l.self_attention.key.weight.data = gpt_model.state_dict()[f'h.{i}.attn.c_attn.weight'][:, d:d*2].T\n",
        "      l.self_attention.key.bias.data = gpt_model.state_dict()[f'h.{i}.attn.c_attn.bias'][d:d*2]\n",
        "      l.self_attention.value.weight.data = gpt_model.state_dict()[f'h.{i}.attn.c_attn.weight'][:, d*2:].T\n",
        "      l.self_attention.value.bias.data = gpt_model.state_dict()[f'h.{i}.attn.c_attn.bias'][d*2:]\n",
        "\n",
        "      # Remap final dense layer in MHA.\n",
        "      l.attention_dense.weight.data = gpt_model.state_dict()[f'h.{i}.attn.c_proj.weight'].T\n",
        "      l.attention_dense.bias.data = gpt_model.state_dict()[f'h.{i}.attn.c_proj.bias']\n",
        "\n",
        "      # Remap attention layer norm.\n",
        "      l.attention_layer_norm.weight.data = gpt_model.state_dict()[f'h.{i}.ln_1.weight']\n",
        "      l.attention_layer_norm.bias.data = gpt_model.state_dict()[f'h.{i}.ln_1.bias']\n",
        "\n",
        "      # Remap post-attention MLP layers.\n",
        "      l.interm_dense.weight.data = gpt_model.state_dict()[f'h.{i}.mlp.c_fc.weight'].T\n",
        "      l.interm_dense.bias.data = gpt_model.state_dict()[f'h.{i}.mlp.c_fc.bias']\n",
        "      l.out_dense.weight.data = gpt_model.state_dict()[f'h.{i}.mlp.c_proj.weight'].T\n",
        "      l.out_dense.bias.data = gpt_model.state_dict()[f'h.{i}.mlp.c_proj.bias']\n",
        "\n",
        "      # Remap second layer norm weights.\n",
        "      l.out_layer_norm.weight.data = gpt_model.state_dict()[f'h.{i}.ln_2.weight']\n",
        "      l.out_layer_norm.bias.data = gpt_model.state_dict()[f'h.{i}.ln_2.bias']\n",
        "\n",
        "    # Remap the final layer norm values.\n",
        "    our_model.final_layer_norm.weight.data = gpt_model.state_dict()['ln_f.weight']\n",
        "    our_model.final_layer_norm.bias.data = gpt_model.state_dict()['ln_f.bias']\n",
        "\n",
        "    return our_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97c95668",
      "metadata": {
        "id": "97c95668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "3be0d1760935451fa0e37a3c52210e19",
            "fe068f7d689b4bd7bcac7c6904ee5a2e",
            "d8cedb21736540cda767580b658d1119",
            "1b124309fc394f55bdb50f5248bee783",
            "cb8338892bf34dfdbfe5a0dad18f45b3",
            "ddd9c3cf77d147ad8d2192d456af2b94",
            "a37a4b690b814a31a5dac0a102e815e5",
            "487e4181ee574d8680ce2e59af91a45d",
            "b8dc271d772244a28f5e90113514b606",
            "ebd26cf0155148faacbd342e61666996",
            "409a6fed972449d38ae9ca20161cd937"
          ]
        },
        "outputId": "94eac762-da17-4d70-a1ea-d212f356389c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3be0d1760935451fa0e37a3c52210e19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your GPT2 implementation is correct!\n"
          ]
        }
      ],
      "source": [
        "# Sanity check: compare with Huggingface GPT2 implementation\n",
        "def test_gpt2(model_size='gpt2'):\n",
        "  sent_ids = torch.tensor([[101, 7592, 2088, 102, 0, 0, 0, 0],\n",
        "                           [101, 7592, 15756, 2897, 2005, 17953, 2361, 102]])\n",
        "  att_mask = torch.tensor([[1, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "\n",
        "  # Load both the OpenAI and your own model.\n",
        "  openai_model = OpenAIGPT2Model.from_pretrained(model_size)\n",
        "  gpt = GPT2Model.from_pretrained(model=model_size, **model_size_to_params(model_size))\n",
        "\n",
        "  outputs = gpt(sent_ids, att_mask)\n",
        "  openai_outputs = openai_model(input_ids=sent_ids, attention_mask=att_mask, output_hidden_states=True).hidden_states[-1]\n",
        "\n",
        "  att_mask = att_mask.unsqueeze(-1)\n",
        "  outputs['last_hidden_state'] = outputs['last_hidden_state'] * att_mask\n",
        "  openai_outputs *= att_mask\n",
        "\n",
        "  assert torch.allclose(outputs['last_hidden_state'], openai_outputs, atol=1e-1, rtol=1e-2)\n",
        "\n",
        "  print(\"Your GPT2 implementation is correct!\")\n",
        "\n",
        "test_gpt2('gpt2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a449a7",
      "metadata": {
        "id": "c3a449a7"
      },
      "source": [
        "## Adam Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "35494be8",
      "metadata": {
        "id": "35494be8"
      },
      "outputs": [],
      "source": [
        "class AdamW(Optimizer):\n",
        "    def __init__(\n",
        "            self,\n",
        "            params: Iterable[torch.nn.parameter.Parameter],\n",
        "            lr: float = 1e-3,\n",
        "            betas: Tuple[float, float] = (0.9, 0.999),\n",
        "            eps: float = 1e-6,\n",
        "            weight_decay: float = 0.0,\n",
        "            correct_bias: bool = True,\n",
        "    ):\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {} - should be >= 0.0\".format(lr))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter: {} - should be in [0.0, 1.0[\".format(betas[1]))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {} - should be >= 0.0\".format(eps))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, correct_bias=correct_bias)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure: Callable = None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
        "\n",
        "                # State should be stored in this dictionary.\n",
        "                state = self.state[p]\n",
        "\n",
        "                # Access hyperparameters from the `group` dictionary.\n",
        "                lr = group[\"lr\"]\n",
        "                eps = group[\"eps\"]\n",
        "                weight_decay = group[\"weight_decay\"]\n",
        "                correct_bias = group[\"correct_bias\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "                state = self.state[p]\n",
        "                if len(state) == 0:\n",
        "                    state[\"step\"] = 0\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(p.data)\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "                t = state[\"step\"]\n",
        "\n",
        "                \"\"\"\n",
        "                TODO-6: Implement the AdamW parameter update for this step.\n",
        "\n",
        "                Implementation hints:\n",
        "                1. Update biased first moment estimate:\n",
        "                    m_t = beta1 * m_{t-1} + (1 - beta1) * grad\n",
        "                2. Update biased second raw moment estimate:\n",
        "                    v_t = beta2 * v_{t-1} + (1 - beta2) * grad^2\n",
        "                3. Apply bias correction if correct_bias=True:\n",
        "                    m_hat = m_t / (1 - beta1^t)\n",
        "                    v_hat = v_t / (1 - beta2^t)\n",
        "                4. Compute step size:\n",
        "                    step_size = lr (or lr / (1 - beta1^t) if bias correction)\n",
        "                5. Update parameters:\n",
        "                    p = p - step_size * m_hat / (sqrt(v_hat) + eps)\n",
        "                6. Apply decoupled weight decay after the parameter update (if weight_decay > 0):\n",
        "                    p = p - lr * weight_decay * p\n",
        "                Reference:\n",
        "                Algorithm 1 in \"Adam: A Method for Stochastic Optimization\"\n",
        "                https://arxiv.org/abs/1412.6980\n",
        "                \"\"\"\n",
        "                ### YOUR CODE HERE\n",
        "\n",
        "                # Update biased first moment estimate: m_t = beta1 * m_{t-1} + (1 - beta1) * grad\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
        "                # Update biased second raw moment estimate: v_t = beta2 * v_{t-1} + (1 - beta2) * grad^2\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n",
        "\n",
        "                # Apply bias correction if correct_bias=True:\n",
        "                if correct_bias:\n",
        "                    # m_hat = m_t / (1 - beta1^t)\n",
        "                    bias_correction1 = 1 - beta1 ** t\n",
        "                    # v_hat = v_t / (1 - beta2^t)\n",
        "                    bias_correction2 = 1 - beta2 ** t\n",
        "                    # Compute step size: step_size = lr / (1 - beta1^t) if bias correction\n",
        "                    step_size = lr * (bias_correction2 ** 0.5) / bias_correction1\n",
        "                else:\n",
        "                    # Compute step size: step_size = lr\n",
        "                    step_size = lr\n",
        "\n",
        "                # Update parameters: p = p - step_size * m_hat / (sqrt(v_hat) + eps)\n",
        "                # Denominator = sqrt(v_hat) + eps\n",
        "                denominator = exp_avg_sq.sqrt().add_(eps)\n",
        "                # Parameter update: p = p - step_size * m_hat / (sqrt(v_hat) + eps)\n",
        "                p.data.addcdiv_(exp_avg, denominator, value=-step_size)\n",
        "\n",
        "                # Apply decoupled weight decay after the parameter update (if weight_decay > 0):\n",
        "                if weight_decay > 0:\n",
        "                    p.data.add_(p.data, alpha=-lr * weight_decay)\n",
        "        return loss\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "544e2a8c",
      "metadata": {
        "id": "544e2a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45e5f49-1bfb-4c35-d54b-980d56bbdb39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5548,  0.8667,  0.0729],\n",
            "        [-0.4472, -0.2951, -0.2717]])\n",
            "tensor([[ 0.5548,  0.8667,  0.0729],\n",
            "        [-0.4472, -0.2951, -0.2717]])\n",
            "Optimizer test passed!\n"
          ]
        }
      ],
      "source": [
        "# Sanity check for AdamW optimizer\n",
        "def test_optimizer(opt_class) -> torch.Tensor:\n",
        "    rng = np.random.default_rng(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    model = torch.nn.Linear(3, 2, bias=False)\n",
        "    opt = opt_class(\n",
        "        model.parameters(),\n",
        "        lr=1e-3,\n",
        "        weight_decay=1e-4,\n",
        "        correct_bias=True,\n",
        "    )\n",
        "    for i in range(1000):\n",
        "        opt.zero_grad()\n",
        "        x = torch.FloatTensor(rng.uniform(size=[model.in_features]))\n",
        "        y_hat = model(x)\n",
        "        y = torch.Tensor([x[0] + x[1], -x[2]])\n",
        "        loss = ((y - y_hat) ** 2).sum()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "    return model.weight.detach()\n",
        "\n",
        "SEED = 0\n",
        "ref = torch.tensor(np.load(\"optimizer_test.npy\"))\n",
        "actual = test_optimizer(AdamW)\n",
        "print(ref)\n",
        "print(actual)\n",
        "assert torch.allclose(ref, actual, atol=1e-6, rtol=1e-4)\n",
        "print(\"Optimizer test passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bde426b",
      "metadata": {
        "id": "8bde426b"
      },
      "source": [
        "## Toy GPT-2 Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f03fffce",
      "metadata": {
        "id": "f03fffce"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch Dataset for preparing text data for language model training.\n",
        "\n",
        "    Each line in the input text file is treated as a separate training example.\n",
        "    The dataset uses a tokenizer to convert text into input IDs and attention masks,\n",
        "    with optional truncation and padding to a fixed maximum sequence length.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the text file. Each line is a separate sample.\n",
        "        tokenizer (PreTrainedTokenizer): Tokenizer to convert text to token IDs.\n",
        "        max_len (int): Maximum sequence length; sequences longer than this are truncated,\n",
        "                       shorter sequences are padded.\n",
        "\n",
        "    Returns per item:\n",
        "        input_ids (torch.Tensor): Token IDs of shape [max_len].\n",
        "        attention_mask (torch.Tensor): Attention mask of shape [max_len], 1 for real tokens, 0 for padding.\n",
        "    \"\"\"\n",
        "    def __init__(self, filepath, tokenizer, max_len):\n",
        "        with open(filepath, 'r') as f:\n",
        "            self.texts = f.read().splitlines()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = enc['input_ids'].squeeze(0)\n",
        "        attention_mask = enc['attention_mask'].squeeze(0)\n",
        "        return input_ids, attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34229c7d",
      "metadata": {
        "id": "34229c7d"
      },
      "outputs": [],
      "source": [
        "# Hyperparamter of toy gpt2 pretraining\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 3\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "CORRECT_BIAS = True\n",
        "HIDDEN_SIZE = 128 # 768 for gpt2\n",
        "NUM_HIDDEN_LAYERS = 2 # 12 for gpt2\n",
        "NUM_ATTENTION_HEADS = 4 # 12 for gpt2\n",
        "MAX_SEQ_LEN = 128 # 1024 for gpt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9ad3e6bc",
      "metadata": {
        "id": "9ad3e6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "a32f268a-9d2a-43ef-da96-462e03cd43cd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1746576030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2Tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meos_token\u001b[0m  \u001b[0;31m# Ensure padding has a pad token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model_config = GPT2Config(\n\u001b[1;32m      5\u001b[0m     \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m                         resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   1995\u001b[0m                             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m                             \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid repo type: {repo_type}. Accepted repo types are: {str(constants.REPO_TYPES)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     hf_headers = build_hf_headers(\n\u001b[0m\u001b[1;32m    970\u001b[0m         \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcustom_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mbuild_hf_headers\u001b[0;34m(token, library_name, library_version, user_agent, headers, is_write_action)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Get auth token to send\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mtoken_to_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token_to_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# Combine headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_headers.py\u001b[0m in \u001b[0;36mget_token_to_send\u001b[0;34m(token)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# Token is not provided: we get it from local cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mcached_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Case token is explicitly required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py\u001b[0m in \u001b[0;36mget_token\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \"\"\"\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_token_from_google_colab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_token_from_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_token_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py\u001b[0m in \u001b[0;36m_get_token_from_google_colab\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF_TOKEN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0m_GOOGLE_COLAB_SECRET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;31m# thread-safe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_userdata_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     resp = _message.blocking_request(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;34m'GetSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Ensure padding has a pad token\n",
        "\n",
        "model_config = GPT2Config(\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
        "    num_attention_heads=NUM_ATTENTION_HEADS,\n",
        "    intermediate_size=HIDDEN_SIZE*3,\n",
        ")\n",
        "\n",
        "toy_gpt2_model = GPT2Model(model_config).to(DEVICE)\n",
        "\n",
        "VOCAB_SIZE = model_config.vocab_size\n",
        "\n",
        "dataset = TextDataset('pretrain.txt', tokenizer, MAX_SEQ_LEN)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "optimizer = AdamW(toy_gpt2_model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, correct_bias=CORRECT_BIAS)\n",
        "\n",
        "\n",
        "global_train_losses = []\n",
        "\n",
        "total_train_loss = 0.0\n",
        "total_train_steps = 0\n",
        "\n",
        "\n",
        "print_interval = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    toy_gpt2_model.train()\n",
        "    for batch_idx, (input_ids, attention_mask) in enumerate(dataloader):\n",
        "        input_ids = input_ids.to(DEVICE)\n",
        "        attention_mask = attention_mask.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hidden_states = toy_gpt2_model(input_ids, attention_mask)['last_hidden_state']  # [B, seq_len, hidden]\n",
        "\n",
        "        \"\"\"\n",
        "        TODO-7: Compute next-token loss from hidden states and update model parameters.\n",
        "\n",
        "        Implementation hints:\n",
        "        1. Convert hidden states to logits over the vocabulary using model.hidden_state_to_token.\n",
        "        2. Shift logits and labels for next-token prediction to align each prediction with the correct next token.\n",
        "        3. Compute the cross-entropy loss.\n",
        "        4. Backpropagate and update parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "\n",
        "        # Convert hidden states to logits over the vocabulary using model.hidden_state_to_token.\n",
        "        logits = toy_gpt2_model.hidden_state_to_token(hidden_states)\n",
        "        # Shift logits and labels for next-token prediction to align each prediction with the correct next token.\n",
        "        logits = logits[:, :-1, :]\n",
        "        labels = input_ids[:, 1:]\n",
        "        # Compute the cross-entropy loss.\n",
        "        loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), labels.reshape(-1))\n",
        "        # Backpropagate and update parameters.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # raise NotImplementedError\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        total_train_steps += 1\n",
        "        global_train_avg_loss = total_train_loss / total_train_steps\n",
        "        global_train_losses.append(global_train_avg_loss)\n",
        "\n",
        "        if batch_idx % print_interval == 0:\n",
        "            print(f\"Train | Epoch {epoch} | Batch {batch_idx} | Global Avg Train Loss: {global_train_avg_loss:.4f}\")\n",
        "\n",
        "    print(f\"Epoch {epoch} finished | Global Avg Train Loss: {global_train_avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1680f9",
      "metadata": {
        "id": "2d1680f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "2c4ece5d-ce64-4804-ea1c-778b9feb7ad9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sanity check: decreasing trend of global average training loss\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(global_train_losses, label=\"Global Avg Train Loss\", color='blue')\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylabel(\"Global Cumulative Avg Loss\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e1a3459",
      "metadata": {
        "id": "5e1a3459"
      },
      "source": [
        "# Task 2: English NLI with GPT-2\n",
        "In this task, you will:\n",
        "- Load a pretrained GPT-2 model with official weights and perform a dummy text generation.\n",
        "- Load an English Natural Language Inference (NLI) dataset.\n",
        "- Fine-tune the loaded model and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b249d1f0",
      "metadata": {
        "id": "b249d1f0"
      },
      "source": [
        "## Model Loading & Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "fc299457",
      "metadata": {
        "id": "fc299457"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_gpt2(model, tokenizer, input_ids, max_gen_length=50, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Generate text from a GPT-2 model given a single input sequence (greedy decoding).\n",
        "\n",
        "    Note:\n",
        "        - Currently only supports batch_size=1 (single input sequence).\n",
        "        - Using greedy decoding, so each run with the same input produces the same output.\n",
        "        - Other sampling-based decoding methods (e.g., top-k, top-p, temperature) can introduce randomness and yield different outputs each run.\n",
        "\n",
        "    Args:\n",
        "        model: GPT-2 model (pretrained or fine-tuned)\n",
        "        tokenizer: GPT-2 tokenizer\n",
        "        input_ids: torch.LongTensor of shape [1, seq_len], input token IDs\n",
        "        max_gen_length: int, maximum number of tokens to generate\n",
        "        device: str, \"cuda\" or \"cpu\"\n",
        "\n",
        "    Returns:\n",
        "        str: Generated text\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    input_ids = input_ids.to(device)  # move input to device\n",
        "    output_ids = input_ids.clone()\n",
        "\n",
        "    \"\"\"\n",
        "    TODO-8: Greedy next-token generation loop\n",
        "\n",
        "    Implementation hints:\n",
        "    Repeat the below steps up to max_gen_length:\n",
        "    1. Construct an attention mask based on current output_ids (non-pad tokens).\n",
        "    2. Pass output_ids and attention_mask through the model to get hidden states.\n",
        "    3. Convert the last hidden state to logits over the vocabulary using model.hidden_state_to_token.\n",
        "    4. Select the next token using greedy decoding (argmax over logits).\n",
        "    5. Append the next token to output_ids.\n",
        "    6. Stop the loop early if the EOS token is generated.\n",
        "\n",
        "    \"\"\"\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # Store initial length to track how many NEW tokens to generate\n",
        "    initial_length = len(output_ids[0])\n",
        "    while len(output_ids[0]) < initial_length + max_gen_length:\n",
        "\n",
        "        # Construct an attention mask based on current output_ids (non-pad tokens).\n",
        "        attention_mask = torch.ones_like(output_ids)\n",
        "\n",
        "        # Pass output_ids and attention_mask through the model to get hidden states.\n",
        "        hidden_states = model(output_ids, attention_mask)['last_hidden_state']\n",
        "\n",
        "        # Convert the last hidden state to logits over the vocabulary using model.hidden_state_to_token.\n",
        "        logits = model.hidden_state_to_token(hidden_states)\n",
        "\n",
        "        # Select the next token using greedy decoding (argmax over logits).\n",
        "        last_token = logits[:, -1, :]   # [batch_size, vocab_size]\n",
        "        next_token = torch.argmax(last_token, dim=1)\n",
        "\n",
        "        # Append the next token to output_ids.\n",
        "        next_token = next_token.unsqueeze(1)    # add sequence dimension\n",
        "        output_ids = torch.cat([output_ids, next_token], dim=1)\n",
        "\n",
        "        # Stop the loop early if the EOS token is generated.\n",
        "        if next_token.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # raise NotImplementedError\n",
        "\n",
        "    # Decode generated tokens to string\n",
        "    ids = output_ids[0]\n",
        "    text = tokenizer.decode(ids, skip_special_tokens=True)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3e7cc58d",
      "metadata": {
        "id": "3e7cc58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "1707dbad9a1642019ff860fdc2d70c44",
            "948641abfecc48aea2dfce48a4da4b83",
            "f0fe9a75259a45eea55e99cb218efce6",
            "f81bd26973774bbfb0e286be3ca066a5",
            "00a9a4c943ba4d838de40b7d9b7df2ed",
            "2bc4ebff1856456999818b4a63a528a4",
            "7be844d1a19343fe99c5885d2979ebe4",
            "1d4b2f81462a4e8a806338e3e4388714",
            "e18c289616794bfd9b5950fd63d2213f",
            "76ec2f4ebab7454c8b9c7c21c0005eb5",
            "cfd178e263ae4cf294991e89b1c9401e",
            "e65d21760c0f40aabcc649ae36e19114",
            "c77642a6e1604ca1b4a1d0c98e68de55",
            "4959063a16a34123aa38677ec420f3eb",
            "fb1ba33627af4e3d812f3d6053b626d5",
            "a75bf1e5f5e348bcb75c4df4d15fed33",
            "f29b46393ed4490bbf9b0c54d83d932e",
            "3e90fc3e8a564ed2a6f32341acc5571a",
            "3be41b98dadb4b5bbf989450cff1d429",
            "5646402e508649679a4773cf31bde1a6",
            "fcba96b6edef4cadb2a5747d87df3b03",
            "b2c450b4a90740e2a5169abe90e631b6",
            "eb64d90a3d9b4358a59b29470452b052",
            "0a4ec23e55444f96ac7a6a65ae45ec04",
            "ef08f17d7906468ab6a8e6b426dde75f",
            "788c157999d54e45b3af81fe96a40aef",
            "5e10a0135b6a4b709058193dba2487e4",
            "acea27534bc64c7eb2c63e92449ffbcd",
            "9deef9eecedd4265b67db928e116aa44",
            "458c9290076a47a992be69f329479db2",
            "62d5ef40d4df47f9b7d1236bd639c514",
            "0015f752c39546a38da9b3f0b6457c7f",
            "a9142ee2da5248b588f5c24a2aab2d21",
            "13a9f02b258e44ffba29e71761a2bcbb",
            "e8e6064b69bf44edbe036e5fbf36db1e",
            "74b8afab89fe42c4b74473afa385e12b",
            "d17336c6ab384470bb32e9728c120f6f",
            "48fa42556c3a4086918ed5b9d3562431",
            "6054543afd2d4e469aee2aef79e2bb20",
            "1d9ed0a92ed94d91a3299e36d7c91b50",
            "d4899dffbd084fcd867b541d372208d5",
            "cc7674391d5f4cadb40966b5af00ac0e",
            "3c424441f2fb46daabd8bd0b0fa2fdb6",
            "1fbaf4cdd10441778ce70379a2ff93c7",
            "f75b362ae71c40878560cd6680df360e",
            "e0f34124c2c44c19b67807208d9258dd",
            "fdedf39acca9457c94aafb9fe54b5443",
            "71c20fb6869f4c64971807b8d8441a98",
            "bf9a8081e5364835be18b106591f5c0c",
            "35259415f24e4282b68545eac15b59a8",
            "0e29feff2c6a4eefacc3ecc44b20a611",
            "a000d52bc9ad4e499a0269f307e2f742",
            "ea09837f2982452dafe88d95d4d12864",
            "b5df1e0d550445c7a43076f1476a0597",
            "ee1e1427b5fb4c2697b64857682fadff",
            "bfe6d0f49c064530a4df0996dcfefe15",
            "de9186a7de394c369afe117fb916967e",
            "8602d16e999441da95ca2e7521536c2a",
            "7ed7a136fb0a4aee88a30d18ddfe3382",
            "15c86c9dba3541f2ac37ff2967d40f9d",
            "f45d53af6ec04d9cb9ecb83820baf331",
            "97369070a5c94d9c99dc18f759061231",
            "465be133b03841cbbc398f64adbbe6c6",
            "75686760234a4b48b1c43d13523e8d84",
            "25d62e4ffa5b4ea8b43fccc0c1c1297d",
            "dd888136c49c47cfbae8e599026c69ea"
          ]
        },
        "outputId": "353c043b-eabc-4426-e023-f6377052d231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1707dbad9a1642019ff860fdc2d70c44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e65d21760c0f40aabcc649ae36e19114"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb64d90a3d9b4358a59b29470452b052"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13a9f02b258e44ffba29e71761a2bcbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f75b362ae71c40878560cd6680df360e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfe6d0f49c064530a4df0996dcfefe15"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load a pretrained GPT-2 model with official weights\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2Model.from_pretrained(\"gpt2\").to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "30d2e14d",
      "metadata": {
        "id": "30d2e14d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc149781-c43c-488f-8268-05390c1c44d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singapore University of Technology and Design (SUTD) is a leading research institute in the field of design and engineering. It is the first university in Singapore to offer a full-time, full-time, full-time, full-time, full-time, full-time, full-time,\n"
          ]
        }
      ],
      "source": [
        "# Dummy text generation using the pretrained GPT-2 model with official weights\n",
        "dummy_texts = \"Singapore University of Technology and Design (SUTD) is\"\n",
        "input_ids = tokenizer(dummy_texts, return_tensors=\"pt\", padding=True)['input_ids']\n",
        "generated_texts = generate_gpt2(model, tokenizer, input_ids, max_gen_length=50, device=DEVICE)\n",
        "print(generated_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0f40935",
      "metadata": {
        "id": "b0f40935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59118287-9a62-42cb-9eb3-9e226c5fbc14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Singapore University of Technology and Design (SUTD) is a $3.\n"
          ]
        }
      ],
      "source": [
        "# Dummy text generation using the toy GPT-2 model trained in Task 1\n",
        "generated_texts = generate_gpt2(toy_gpt2_model, tokenizer, input_ids, max_gen_length=50, device=DEVICE)\n",
        "print(generated_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b611373",
      "metadata": {
        "id": "7b611373"
      },
      "source": [
        "## Load NLI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "19f25161",
      "metadata": {
        "id": "19f25161"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(preds, labels):\n",
        "    correct = sum(p.lower().strip() == l.lower().strip() for p, l in zip(preds, labels))\n",
        "    return correct / len(labels)\n",
        "\n",
        "def evaluate_gpt2_xnli(model, tokenizer, dataloader, max_gen_length=10, device=\"cuda\"):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for item in tqdm(dataloader, desc=\"Generating\"):\n",
        "            input_ids = item['input_ids']\n",
        "            gen_text = generate_gpt2(model, tokenizer, input_ids, max_gen_length=max_gen_length, device=device)\n",
        "            pred_label = gen_text.split(\"Label:\")[-1].strip()\n",
        "            all_preds.append(pred_label)\n",
        "            all_labels.extend(item['label_strs'])\n",
        "    acc = compute_accuracy(all_preds, all_labels)\n",
        "    print(f\"Evaluation accuracy: {acc*100:.2f}%\")\n",
        "    return acc, all_preds, all_labels\n",
        "\n",
        "class XNLIDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch Dataset for XNLI (Cross-lingual Natural Language Inference) task.\n",
        "\n",
        "    Supports train, dev, and test splits in a specific language,\n",
        "    tokenizes text inputs for GPT-style models, and optionally subsamples the dataset.\n",
        "\n",
        "    Attributes:\n",
        "        split (str): Dataset split, one of 'train', 'dev', 'test'.\n",
        "        lang (str): Language code (e.g., 'en', 'zh').\n",
        "        tokenizer: A HuggingFace tokenizer to convert text to input IDs.\n",
        "        max_length (int): Maximum sequence length for tokenization.\n",
        "        LABEL2ID (dict): Mapping from textual labels to integer IDs.\n",
        "        ID2LABEL (dict): Reverse mapping from integer IDs to textual labels.\n",
        "        data (pd.DataFrame): The loaded and preprocessed dataset.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        split=\"train\",\n",
        "        lang=\"en\",\n",
        "        train_path_template=\"XNLI-MT-1.0/multinli/multinli.train.{lang}.tsv\",\n",
        "        test_path=\"XNLI-1.0/xnli.test.tsv\",\n",
        "        dev_path=\"XNLI-1.0/xnli.dev.tsv\",\n",
        "        tokenizer=None,\n",
        "        max_length=1024,\n",
        "        subset = 1.0  # 0~1\n",
        "    ):\n",
        "        self.split = split\n",
        "        self.lang = lang\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.LABEL2ID = {\"entailment\": 0, \"contradictory\": 1, \"neutral\": 2}\n",
        "        self.ID2LABEL = {v: k for k, v in self.LABEL2ID.items()}\n",
        "\n",
        "        if split == \"train\":\n",
        "            path = train_path_template.format(lang=lang)\n",
        "            df = self.read_xnli_tsv(path, split)\n",
        "            df = df.dropna(subset=['premise','hypo','label'])\n",
        "        elif split in [\"dev\", \"test\"]:\n",
        "            path = test_path if split==\"test\" else dev_path\n",
        "            df = self.read_xnli_tsv(path, split)\n",
        "            df = df[df['language']==lang].copy()\n",
        "            keep_cols = ['sentence1', 'sentence2', 'gold_label']\n",
        "            df = df[keep_cols].dropna()\n",
        "            df.rename(columns={'sentence1':'premise','sentence2':'hypo','gold_label':'label'}, inplace=True)\n",
        "            df['label'] = df['label'].replace({'contradiction': 'contradictory'})\n",
        "        else:\n",
        "            raise ValueError(\"split must be one of ['train','dev','test']\")\n",
        "\n",
        "        original_num = len(df)\n",
        "        if subset < 1.0:\n",
        "            n = max(1, int(len(df) * subset))\n",
        "            df = df.iloc[:n].reset_index(drop=True)\n",
        "        subset_num = len(df)\n",
        "\n",
        "        self.data = df.reset_index(drop=True)\n",
        "        print(f\"Dataset initialized: split='{split}', lang='{lang}', total={original_num}, subset={subset}, subset_count={subset_num}\")\n",
        "\n",
        "    def read_xnli_tsv(self, path, split):\n",
        "        \"\"\"\n",
        "        Read an XNLI TSV file and return it as a pandas DataFrame.\n",
        "\n",
        "        Args:\n",
        "            path (str): Path to the TSV file.\n",
        "            split (str): One of \"train\", \"dev\", \"test\" indicating the dataset split.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: The dataset as a DataFrame with appropriate columns.\n",
        "        \"\"\"\n",
        "        if split == \"train\":\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                lines = f.read().splitlines()\n",
        "            header = lines[0].split(\"\\t\")\n",
        "            data = []\n",
        "            for i, line in enumerate(lines[1:], start=2):\n",
        "                parts = line.split(\"\\t\")\n",
        "                if len(parts) == len(header):\n",
        "                    data.append(parts)\n",
        "                else:\n",
        "                    print(f\"skip row {i}: {len(parts)} cols → {parts[:2]}\")\n",
        "        else:\n",
        "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "                reader = csv.reader(f, delimiter=\"\\t\")\n",
        "                rows = list(reader)\n",
        "            header = rows[0]\n",
        "            expected_cols = len(header)\n",
        "            data = []\n",
        "            for i, row in enumerate(rows[1:], start=2):\n",
        "                if len(row) == expected_cols:\n",
        "                    data.append(row)\n",
        "                else:\n",
        "                    print(f\"skip row {i}: {len(row)} cols → {row[:2]}\")\n",
        "        return pd.DataFrame(data, columns=header)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of examples in the dataset.\"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieve a single example by index and tokenize it.\n",
        "\n",
        "        For training split:\n",
        "            - Constructs the input as \"Premise: ... Hypothesis: ... Label: ...\"\n",
        "            - Tokenizes the full input.\n",
        "            - Masks the prefix tokens in the labels with -100 for GPT loss computation.\n",
        "\n",
        "        For dev/test split:\n",
        "            - Constructs the input without label as \"Premise: ... Hypothesis: ... Label:\"\n",
        "\n",
        "        Returns:\n",
        "            dict: Contains 'input_ids', 'attention_mask', 'labels' (train only), 'label_str'\n",
        "        \"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "        premise = row['premise']\n",
        "        hypo = row['hypo']\n",
        "        label = row['label']\n",
        "        if self.lang == 'zh': # de-tokenize for Chinese\n",
        "            premise = premise.replace(\" \", \"\")\n",
        "            hypo = hypo.replace(\" \", \"\")\n",
        "\n",
        "        if self.split == \"train\":\n",
        "            prefix = f\"Premise: {premise}\\nHypothesis: {hypo}\\nLabel:\"\n",
        "            full_text = prefix + str(self.LABEL2ID[label])\n",
        "            tokenized = self.tokenizer(\n",
        "                full_text,\n",
        "                truncation=True,\n",
        "                max_length=self.max_length,\n",
        "                padding=False,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            tokenized = {k: v.squeeze(0) for k, v in tokenized.items()}\n",
        "\n",
        "            prefix_ids = self.tokenizer(prefix).input_ids\n",
        "            labels_ids = tokenized['input_ids'].clone()\n",
        "            labels_ids[:len(prefix_ids)] = -100 # Masks the prefix tokens in the labels with -100 for GPT loss computation.\n",
        "            tokenized['labels'] = labels_ids\n",
        "            tokenized['label_str'] = str(self.LABEL2ID[label])\n",
        "            return tokenized\n",
        "        else:\n",
        "            text = f\"Premise: {premise}\\nHypothesis: {hypo}\\nLabel:\"\n",
        "            tokenized = self.tokenizer(\n",
        "                text,\n",
        "                truncation=True,\n",
        "                max_length=self.max_length,\n",
        "                padding=False,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            tokenized = {k: v.squeeze(0) for k, v in tokenized.items()}\n",
        "            tokenized['label_str'] = str(self.LABEL2ID[label])\n",
        "            return tokenized\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch):\n",
        "        \"\"\"\n",
        "        Collate a batch of examples into padded tensors.\n",
        "\n",
        "        Pads 'input_ids' and 'attention_mask' to the max length in the batch.\n",
        "        Pads 'labels' with -100 if present.\n",
        "        Collects 'label_str' for reference.\n",
        "\n",
        "        Returns:\n",
        "            dict: Padded tensors and label strings for the batch.\n",
        "        \"\"\"\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            [b['input_ids'] for b in batch],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "        attention_mask = torch.nn.utils.rnn.pad_sequence(\n",
        "            [b['attention_mask'] for b in batch],\n",
        "            batch_first=True,\n",
        "            padding_value=0\n",
        "        )\n",
        "\n",
        "        if 'labels' in batch[0]:\n",
        "            labels = torch.nn.utils.rnn.pad_sequence(\n",
        "                [b['labels'] for b in batch],\n",
        "                batch_first=True,\n",
        "                padding_value=-100\n",
        "            )\n",
        "        else:\n",
        "            labels = None\n",
        "\n",
        "        label_strs = [b['label_str'] for b in batch]\n",
        "\n",
        "        out = {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"label_strs\": label_strs}\n",
        "        if labels is not None:\n",
        "            out[\"labels\"] = labels\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0fa19d5f",
      "metadata": {
        "id": "0fa19d5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331e37b2-7201-4fd2-9d2a-f829ab17f5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset initialized: split='train', lang='en', total=392702, subset=1, subset_count=392702\n",
            "Dataset initialized: split='dev', lang='en', total=2490, subset=1, subset_count=2490\n",
            "Dataset initialized: split='test', lang='en', total=5010, subset=1, subset_count=5010\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Load NLI datasets for fine-tuning and evaluation.\n",
        "For debugging on a CPU, you can set SUBSET to a float in (0,1) to load only a fraction of the data.\n",
        "Final training and evaluation should use the full dataset (SUBSET=1).\n",
        "\"\"\"\n",
        "\n",
        "TRAIN_SUBSET = 1\n",
        "DEV_SUBSET = 1\n",
        "TEST_SUBSET = 1\n",
        "\n",
        "train_dataset = XNLIDataset(\n",
        "    split=\"train\",\n",
        "    lang=\"en\",\n",
        "    tokenizer=tokenizer,\n",
        "    subset=TRAIN_SUBSET\n",
        ")\n",
        "\n",
        "dev_dataset = XNLIDataset(\n",
        "    split=\"dev\",\n",
        "    lang=\"en\",\n",
        "    tokenizer=tokenizer,\n",
        "    subset=DEV_SUBSET\n",
        ")\n",
        "\n",
        "test_dataset = XNLIDataset(\n",
        "    split=\"test\",\n",
        "    lang=\"en\",\n",
        "    tokenizer=tokenizer,\n",
        "    subset=TEST_SUBSET\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3196cd4",
      "metadata": {
        "id": "f3196cd4"
      },
      "source": [
        "## Fine-tune GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aaf7bfd",
      "metadata": {
        "id": "5aaf7bfd"
      },
      "outputs": [],
      "source": [
        "# Hyperparamter of gpt2 fine-tuning\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 4\n",
        "LR = 5e-5\n",
        "WEIGHT_DECAY = 0.01\n",
        "CORRECT_BIAS = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8142b5",
      "metadata": {
        "id": "5e8142b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e50bd6f-7076-4466-958a-249b7a586870"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 98176/98176 [1:57:03<00:00, 13.98it/s, avg_loss=0.6160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished | Global Avg Loss: 0.6160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 2490/2490 [00:34<00:00, 72.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 79.52%\n",
            "New best model saved at best_model/model.pt with dev accuracy 79.52%\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoaders for training and validation datasets\n",
        "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=XNLIDataset.collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset,shuffle=False,collate_fn=XNLIDataset.collate_fn)\n",
        "\n",
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY, correct_bias=CORRECT_BIAS)\n",
        "# Track training progress\n",
        "global_train_losses = []\n",
        "total_train_loss = 0.0\n",
        "total_train_steps = 0\n",
        "print_interval = 10\n",
        "\n",
        "# Track best dev accuracy for model saving\n",
        "# This only works for epoch > 1\n",
        "best_dev_acc = 0.0\n",
        "SAVE_DIR = \"best_model\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "    model.train()\n",
        "    # Iterate over batches\n",
        "    loop = tqdm(train_loader, desc=\"Training\")\n",
        "    for batch in loop:\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)        # [B, seq_len]\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "        labels = batch.get(\"labels\").to(DEVICE)                    # [B, seq_len]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        hidden_states = model(input_ids=input_ids, attention_mask=attention_mask)['last_hidden_state']  # [B, seq_len, hidden]\n",
        "\n",
        "        \"\"\"\n",
        "        TODO-9: Compute next-token loss from hidden states and update model parameters.\n",
        "\n",
        "        Implementation hints:\n",
        "        1. Convert hidden states to logits over the vocabulary using model.hidden_state_to_token.\n",
        "        2. Shift logits and labels for next-token prediction to align each prediction with the correct next token.\n",
        "        3. Compute the cross-entropy loss, making sure positions with label=-100 are ignored.\n",
        "        4. Backpropagate and update model parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "\n",
        "        # Convert hidden states to logits over the vocabulary using model.hidden_state_to_token.\n",
        "        logits = model.hidden_state_to_token(hidden_states)\n",
        "\n",
        "        # Shift logits and labels for next-token prediction to align each prediction with the correct next token.\n",
        "        logits = logits[:, :-1, :]\n",
        "        labels = labels[:, 1:]\n",
        "\n",
        "        # Compute the cross-entropy loss, making sure positions with label=-100 are ignored.\n",
        "        loss = F.cross_entropy(logits.reshape(-1, logits.size(-1)), labels.reshape(-1), ignore_index=-100)\n",
        "\n",
        "        # Backpropagate and update the model parameters.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # raise NotImplementedError\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        total_train_steps += 1\n",
        "        global_train_avg_loss = total_train_loss / total_train_steps\n",
        "        global_train_losses.append(global_train_avg_loss)\n",
        "\n",
        "        loop.set_postfix({'avg_loss': f\"{global_train_avg_loss:.4f}\"})\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished | Global Avg Loss: {global_train_avg_loss:.4f}\")\n",
        "\n",
        "    acc, all_preds, all_labels = evaluate_gpt2_xnli(model, tokenizer, dev_loader, max_gen_length=1, device=DEVICE)\n",
        "\n",
        "\n",
        "    if acc > best_dev_acc:\n",
        "        best_dev_acc = acc\n",
        "        torch.save(model.state_dict(), f\"{SAVE_DIR}/model.pt\")\n",
        "        print(f\"New best model saved at {SAVE_DIR}/model.pt with dev accuracy {best_dev_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostic: Check what the model is actually generating\n",
        "# Run this after training to debug 0% accuracy issues\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"DIAGNOSTIC: Checking model predictions\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get a few examples from dev set\n",
        "model.eval()\n",
        "sample_batch = next(iter(dev_loader))\n",
        "input_ids_sample = sample_batch['input_ids'][:3].to(DEVICE)\n",
        "labels_sample = sample_batch['label_strs'][:3]\n",
        "\n",
        "print(f\"\\nExpected labels: {labels_sample}\")\n",
        "print(\"\\nGenerated outputs:\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (input_id, true_label) in enumerate(zip(input_ids_sample, labels_sample)):\n",
        "        input_id = input_id.unsqueeze(0)  # Add batch dimension\n",
        "        gen_text = generate_gpt2(model, tokenizer, input_id, max_gen_length=5, device=DEVICE)\n",
        "\n",
        "        # Try different parsing methods\n",
        "        pred_raw = gen_text.split(\"Label:\")[-1].strip()\n",
        "\n",
        "        # Extract first digit if present\n",
        "        import re\n",
        "        digits = re.findall(r'\\d+', pred_raw)\n",
        "        pred_digit = digits[0] if digits else \"NO_DIGIT\"\n",
        "\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"  Full generated text: {repr(gen_text)}\")\n",
        "        print(f\"  After 'Label:': {repr(pred_raw)}\")\n",
        "        print(f\"  Extracted digit: {pred_digit}\")\n",
        "        print(f\"  True label: {true_label}\")\n",
        "        print(f\"  Match: {pred_digit == true_label}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"If you see 'NO_DIGIT' or mismatches, the model isn't generating\")\n",
        "print(\"the expected format. Try increasing max_gen_length or check training.\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "4kuf5U2zv0jK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4becd2e-7208-46db-f00f-7456d2d9c459"
      },
      "id": "4kuf5U2zv0jK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DIAGNOSTIC: Checking model predictions\n",
            "============================================================\n",
            "\n",
            "Expected labels: ['2']\n",
            "\n",
            "Generated outputs:\n",
            "\n",
            "Example 1:\n",
            "  Full generated text: \"Premise: And he said, Mama, I'm home.\\nHypothesis: He called his mom as soon as the school bus dropped him off.\\nLabel:22222\"\n",
            "  After 'Label:': '22222'\n",
            "  Extracted digit: 22222\n",
            "  True label: 2\n",
            "  Match: False\n",
            "\n",
            "============================================================\n",
            "If you see 'NO_DIGIT' or mismatches, the model isn't generating\n",
            "the expected format. Try increasing max_gen_length or check training.\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3656cf81",
      "metadata": {
        "id": "3656cf81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802047b0-9c7e-4ef7-c60a-588595ea05e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:12<00:00, 69.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 78.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Sanity check: after fine-tuning, the accuracy should be better than random guessing (33.33%)\n",
        "# The accuracy we got is around 77.96% using whole training data and 1 epoch\n",
        "SAVE_DIR = \"best_model\"\n",
        "finetuned_model = GPT2Model(GPT2Config()).to(DEVICE)\n",
        "finetuned_model.load_state_dict(torch.load(f\"{SAVE_DIR}/model.pt\"))\n",
        "test_loader = DataLoader(test_dataset,shuffle=False,collate_fn=XNLIDataset.collate_fn)\n",
        "acc, all_preds, all_labels = evaluate_gpt2_xnli(finetuned_model, tokenizer, test_loader, max_gen_length=1, device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "354805ec",
      "metadata": {
        "id": "354805ec"
      },
      "source": [
        "# Task 3: Multilingual NLI with GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd0ee4ba",
      "metadata": {
        "id": "fd0ee4ba"
      },
      "source": [
        "In this task, you will:\n",
        "\n",
        "- Test the fine-tuned GPT-2 on non-English languages for zero-shot cross-lingual transfer.\n",
        "\n",
        "- For each non-English language, fine-tune a model on the corresponding training set.\n",
        "\n",
        "- Fine-tune a unified model on the training sets of all languages."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd57fdf1",
      "metadata": {
        "id": "dd57fdf1"
      },
      "source": [
        "## Zero-shot Cross-lingual Transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a247f1d0",
      "metadata": {
        "id": "a247f1d0"
      },
      "outputs": [],
      "source": [
        "langs = ['en', 'ar', 'bg', 'de','el','es','fr','hi','ru','sw','th','tr','ur','vi','zh']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1f58b2",
      "metadata": {
        "id": "ff1f58b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a716bc-8a07-4ee4-f1f4-8f360f918359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset initialized: split='test', lang='en', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='ar', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='bg', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='de', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='el', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='es', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='fr', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='hi', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='ru', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='sw', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='th', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='tr', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='ur', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='vi', total=5010, subset=1, subset_count=5010\n",
            "Dataset initialized: split='test', lang='zh', total=5010, subset=1, subset_count=5010\n",
            "Evaluating on en...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:09<00:00, 72.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 78.82%\n",
            "Evaluating zero-shot on ar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:18<00:00, 63.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 35.89%\n",
            "Evaluating zero-shot on bg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:22<00:00, 60.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 37.23%\n",
            "Evaluating zero-shot on de...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:12<00:00, 69.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 40.76%\n",
            "Evaluating zero-shot on el...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:24<00:00, 59.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 35.09%\n",
            "Evaluating zero-shot on es...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:11<00:00, 69.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 46.17%\n",
            "Evaluating zero-shot on fr...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:12<00:00, 69.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 42.18%\n",
            "Evaluating zero-shot on hi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:27<00:00, 57.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 34.77%\n",
            "Evaluating zero-shot on ru...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:22<00:00, 60.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 37.64%\n",
            "Evaluating zero-shot on sw...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:12<00:00, 69.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 36.51%\n",
            "Evaluating zero-shot on th...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:32<00:00, 54.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 34.71%\n",
            "Evaluating zero-shot on tr...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:13<00:00, 67.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 38.00%\n",
            "Evaluating zero-shot on ur...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:23<00:00, 60.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 34.89%\n",
            "Evaluating zero-shot on vi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:18<00:00, 63.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 36.97%\n",
            "Evaluating zero-shot on zh...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating: 100%|██████████| 5010/5010 [01:15<00:00, 65.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation accuracy: 37.62%\n",
            "Zero-shot cross-lingual accuracy per language:\n",
            "en: 78.82%\n",
            "ar: 35.89%\n",
            "bg: 37.23%\n",
            "de: 40.76%\n",
            "el: 35.09%\n",
            "es: 46.17%\n",
            "fr: 42.18%\n",
            "hi: 34.77%\n",
            "ru: 37.64%\n",
            "sw: 36.51%\n",
            "th: 34.71%\n",
            "tr: 38.00%\n",
            "ur: 34.89%\n",
            "vi: 36.97%\n",
            "zh: 37.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "TEST_SUBSET = 1\n",
        "path = f\"{SAVE_DIR}/model.pt\"\n",
        "finetuned_model = GPT2Model(GPT2Config()).to(DEVICE)\n",
        "finetuned_model.load_state_dict(torch.load(path))\n",
        "all_test_datasets = {}\n",
        "all_test_loader = {}\n",
        "for lang in langs:\n",
        "    test_dataset = XNLIDataset(split=\"test\", lang=lang, tokenizer=tokenizer, max_length=1024, subset=TEST_SUBSET)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=XNLIDataset.collate_fn)\n",
        "    all_test_datasets[lang] = test_dataset\n",
        "    all_test_loader[lang] = test_loader\n",
        "\n",
        "all_results = {}\n",
        "for lang in langs:\n",
        "    test_loader = all_test_loader[lang]\n",
        "    if lang == \"en\":\n",
        "        print(f\"Evaluating on {lang}...\")\n",
        "    else:\n",
        "        print(f\"Evaluating zero-shot on {lang}...\")\n",
        "    acc, all_preds, all_labels = evaluate_gpt2_xnli(finetuned_model, tokenizer, test_loader, max_gen_length=1, device=DEVICE)\n",
        "    all_results[lang] = acc\n",
        "\n",
        "print(\"Zero-shot cross-lingual accuracy per language:\")\n",
        "for lang, acc in all_results.items():\n",
        "    print(f\"{lang}: {acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "491d87e2",
      "metadata": {
        "id": "491d87e2"
      },
      "source": [
        "## Fertility-based Language Selection\n",
        "\n",
        "Guidance: You may notice that some languages achieve reasonable zero-shot cross-lingual performance. This is likely because these languages are closer to English (e.g., in writing system), making cross-lingual transfer from English easier. However, many other languages perform close to random guessing, which is expected since GPT-2 was pretrained entirely on English data.\n",
        "\n",
        "To perform further multilingual fine-tuning, we need to identify which languages GPT-2 can realistically support (because if a language is not supported, fine-tuning on it will have little effect). A straightforward way to check this is to inspect the tokens in the model’s tokenizer. However, this is not practical for GPT-2-like models, because they use a Byte-Pair Encoding (BPE) tokenizer. BPE can decompose any Unicode string into subwords, even if the string never appeared in training, making it difficult to determine whether a language is truly supported.\n",
        "\n",
        "Instead, we can approximate tokenizer support using fertility, a metric that measures the average number of subwords produced per word. Lower fertility indicates better tokenizer quality and compression, while high fertility suggests heavy fragmentation, which can hurt model performance. By combining fertility analysis with zero-shot cross-lingual results, we can identify a subset of languages that GPT-2 can reasonably handle (a rough estimate, as officially GPT-2 is designed for English). Then, we can proceed with multilingual fine-tuning experiments on these languages.\n",
        "\n",
        "Reference: How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28acaf7",
      "metadata": {
        "id": "d28acaf7"
      },
      "outputs": [],
      "source": [
        "def compute_fertility(dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Compute average fertility for a dataset.\n",
        "    Fertility = #tokens / #words\n",
        "    Note: word splitting is approximate and uses whitespace.\n",
        "    \"\"\"\n",
        "    total_words = 0\n",
        "    total_tokens = 0\n",
        "    samples = len(dataset)\n",
        "\n",
        "    for i in tqdm(range(samples), desc=\"Computing fertility\"):\n",
        "        row = dataset.data.iloc[i]\n",
        "        for sent in [row['premise'], row['hypo']]:\n",
        "            words = sent.strip().split()  # crude word estimate\n",
        "            tokens = tokenizer.tokenize(sent)\n",
        "            total_words += len(words)\n",
        "            total_tokens += len(tokens)\n",
        "\n",
        "    fertility = total_tokens / total_words if total_words > 0 else 0.0\n",
        "    return fertility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce5b291",
      "metadata": {
        "id": "6ce5b291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7d2d51-1c8e-4a9a-8412-cf7892c3b4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset initialized: split='train', lang='en', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:00<00:00, 4439.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en: fertility = 1.11\n",
            "Dataset initialized: split='train', lang='ar', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2442.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ar: fertility = 4.70\n",
            "Dataset initialized: split='train', lang='bg', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2188.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bg: fertility = 5.53\n",
            "Dataset initialized: split='train', lang='de', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2811.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "de: fertility = 2.10\n",
            "Dataset initialized: split='train', lang='el', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2130.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el: fertility = 6.16\n",
            "Dataset initialized: split='train', lang='es', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 3058.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "es: fertility = 1.83\n",
            "Dataset initialized: split='train', lang='fr', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 3047.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fr: fertility = 1.75\n",
            "Dataset initialized: split='train', lang='hi', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2432.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi: fertility = 5.12\n",
            "Dataset initialized: split='train', lang='ru', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2019.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ru: fertility = 5.90\n",
            "Dataset initialized: split='train', lang='sw', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:00<00:00, 3952.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sw: fertility = 2.08\n",
            "Dataset initialized: split='train', lang='th', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 2472.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th: fertility = 9.48\n",
            "Dataset initialized: split='train', lang='tr', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 3051.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tr: fertility = 2.73\n",
            "Dataset initialized: split='train', lang='ur', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 3607.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ur: fertility = 5.16\n",
            "Dataset initialized: split='train', lang='vi', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 3588.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vi: fertility = 3.62\n",
            "Dataset initialized: split='train', lang='zh', total=392702, subset=0.01, subset_count=3927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing fertility: 100%|██████████| 3927/3927 [00:01<00:00, 3758.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "zh: fertility = 3.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "subset_for_check = 0.01\n",
        "\n",
        "for lang in langs:\n",
        "    train_dataset = XNLIDataset(\n",
        "        split=\"train\",\n",
        "        lang=lang,\n",
        "        tokenizer=tokenizer,\n",
        "        subset=subset_for_check\n",
        "    )\n",
        "    fertility_score = compute_fertility(train_dataset, tokenizer)\n",
        "    print(f\"{lang}: fertility = {fertility_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37090f47",
      "metadata": {
        "id": "37090f47"
      },
      "source": [
        "## Fine-tune GPT-2 (per-language)\n",
        "\n",
        "Guidance: Load the pretrained GPT-2 (not the ones fine-tuned on English NLI) along with the training data for a single target language. Choose non-English languages that performed well in the zero-shot cross-lingual transfer and fertility evaluation. It depends on you how many languages to include. Fine-tune a separate model for each selected language. Afterwards, compare these per-language fine-tuned models with the zero-shot cross-lingual transfer results."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2cb1bee",
      "metadata": {
        "id": "c2cb1bee"
      },
      "source": [
        "## Fine-tune GPT-2 (all)\n",
        "\n",
        "Guidance: Load the pretrained GPT-2 (again, not the ones fine-tuned on English NLI) along with the training data for all target languages, including English. For non-English languages, select those that performed well in the zero-shot cross-lingual transfer and fertility evaluation. It depends on you how many languages to include. Fine-tune a single model on this combined multilingual dataset. Afterwards, compare this model with the per-language fine-tuned models and the zero-shot cross-lingual transfer results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QWEN MODEL"
      ],
      "metadata": {
        "id": "xKhk-ISGe4Pj"
      },
      "id": "xKhk-ISGe4Pj"
    },
    {
      "cell_type": "code",
      "source": [
        "# import Qwen\n",
        "qwen_model_name = \"Qwen/Qwen2-0.5B\"\n",
        "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_model_name, trust_remote_code=True)\n",
        "qwen_tokenizer.pad_token = qwen_tokenizer.eos_token\n",
        "\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
        "  qwen_model_name,\n",
        "  torch_dtype=torch.bfloat32,\n",
        "  device_map=\"auto\",\n",
        "  trust_remote_code=True\n",
        ")"
      ],
      "metadata": {
        "id": "xGA4Hqdze3Kf"
      },
      "id": "xGA4Hqdze3Kf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using LoRA for optimised parameter training\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "# Apply LoRA\n",
        "qwen_model = get_peft_model(qwen_model, lora_config)"
      ],
      "metadata": {
        "id": "YyzO1xYEfvf2"
      },
      "id": "YyzO1xYEfvf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htcEUuhbgtVR"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1\n",
        "BATCH_SIZE = 32\n",
        "LR = 2e-4\n",
        "WEIGHT_DECAY = 0.01\n",
        "CORRECT_BIAS = True"
      ],
      "id": "htcEUuhbgtVR"
    },
    {
      "cell_type": "code",
      "source": [
        "def qwen_finetuned(qwen_model, qwen_tokenizer):\n",
        "  # training dataset\n",
        "  train_dataset = XNLIDataset(\n",
        "          split=\"train\",\n",
        "          lang=\"en\",\n",
        "          tokenizer=qwen_tokenizer,\n",
        "          subset=TRAIN_SUBSET\n",
        "      )\n",
        "\n",
        "  train_loader = DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      shuffle=True,\n",
        "      collate_fn=XNLIDataset.collate_fn\n",
        "  )\n",
        "\n",
        "  qwen_model.to(DEVICE)\n",
        "  optimizer = AdamW(qwen_model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "  # Enable automatic mixed precision\n",
        "  scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "  global_train_losses = []\n",
        "  total_train_loss = 0.0\n",
        "  total_train_steps = 0\n",
        "  print_interval = 100\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch}\")\n",
        "    qwen_model.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE, non_blocking=True)\n",
        "        attention_mask = batch[\"attention_mask\"].to(DEVICE, non_blocking=True)\n",
        "        labels = batch.get(\"labels\").to(DEVICE, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision training\n",
        "        with torch.cuda.amp.autocast(dtype=torch.bfloat16):  # A100 optimized\n",
        "            outputs = qwen_model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "\n",
        "        # Scale loss and backward\n",
        "        if scaler:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_value = loss.item()\n",
        "        total_train_loss += loss_value\n",
        "        total_train_steps += 1\n",
        "        global_train_avg_loss = total_train_loss / total_train_steps\n",
        "        global_train_losses.append(global_train_avg_loss)\n",
        "\n",
        "        if batch_idx % print_interval == 0:\n",
        "          print(f\"Train | Epoch {epoch} | Batch {batch_idx} | Global Avg Train Loss: {global_train_avg_loss:.4f} | Current Loss: {loss_value:.4f}\")\n",
        "\n",
        "\n",
        "  print(\"Training Complete.\")\n",
        "  return qwen_model"
      ],
      "metadata": {
        "id": "IfgnZJhEggrl"
      },
      "id": "IfgnZJhEggrl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# actual training\n",
        "lora_adapter = qwen_finetuned(qwen_model, qwen_tokenizer)\n",
        "lora_adapter.save_pretrained(\"./qwen_finetuned_2hr\")\n",
        "lora_adapter.save_pretrained(\"./qwen_finetuned_2hr\")"
      ],
      "metadata": {
        "id": "yoUj8CFul7Oc"
      },
      "id": "yoUj8CFul7Oc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_nli(model, tokenizer, dataloader, model_type=\"gpt2\", device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Unified evaluation for BOTH GPT-2 and Qwen\n",
        "    - model_type: \"gpt2\" or \"qwen\"\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=f\"Evaluating {model_type}\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device) if 'attention_mask' in batch else None\n",
        "            true_labels = batch['label_strs']\n",
        "\n",
        "            if model_type == \"gpt2\":\n",
        "                gen_text = generate_gpt2(model, tokenizer, input_ids, max_gen_length=1, device=device)\n",
        "                pred_label = gen_text.split(\"Label:\")[-1].strip()\n",
        "                all_preds.append(pred_label)\n",
        "            else:\n",
        "                generated_ids = model.generate(\n",
        "                    input_ids=input_ids,\n",
        "                    attention_mask=attention_mask,\n",
        "                    max_new_tokens=1,\n",
        "                    do_sample=False,\n",
        "                    pad_token_id=tokenizer.pad_token_id,\n",
        "                    eos_token_id=tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "                # Decode predictions\n",
        "                for i in range(len(generated_ids)):\n",
        "                    # Get only newly generated tokens\n",
        "                    input_len = input_ids[i].shape[0]\n",
        "                    generated_tokens = generated_ids[i][input_len:]\n",
        "                    gen_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "\n",
        "                    # Extract label\n",
        "                    pred_label = gen_text.strip()\n",
        "                    all_preds.append(pred_label)\n",
        "\n",
        "            all_labels.extend(true_labels)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct = sum(p == l for p, l in zip(all_preds, all_labels))\n",
        "    accuracy = correct / len(all_labels)\n",
        "\n",
        "    print(f\"{model_type.upper()} Evaluation accuracy: {accuracy*100:.2f}%\")\n",
        "    return accuracy, all_preds, all_labels"
      ],
      "metadata": {
        "id": "18pCjlIdk3nZ"
      },
      "id": "18pCjlIdk3nZ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "adapter_path = \"/content/drive/MyDrive/kp-gpt2-nlp/qwen_finetuned_2hr\"\n",
        "\n",
        "# Load base model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    qwen_model_name,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "lora_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "\n",
        "# Merge adapter (in-memory)\n",
        "qwen_finetuned = lora_model.merge_and_unload()\n",
        "\n",
        "# Now you can use it\n",
        "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_model_name)\n",
        "\n",
        "# Set padding token if needed\n",
        "if qwen_tokenizer.pad_token is None:\n",
        "    qwen_tokenizer.pad_token = qwen_tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "j9G0yHMVUD5Y"
      },
      "id": "j9G0yHMVUD5Y",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SUBSET = 1\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "test_languages = ['en', 'th', 'ar', 'de', 'zh']\n",
        "results = {'gpt2': {}, 'qwen': {}}\n",
        "\n",
        "for lang in test_languages:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Testing on {lang}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Load data once\n",
        "    test_dataset_raw = XNLIDataset(\n",
        "        split=\"test\",\n",
        "        lang=lang,\n",
        "        tokenizer=tokenizer,\n",
        "        subset=TEST_SUBSET\n",
        "    )\n",
        "\n",
        "    # Get the actual labels\n",
        "    true_labels = []\n",
        "    for i in range(len(test_dataset_raw)):\n",
        "        true_labels.append(test_dataset_raw.data.iloc[i]['label'])\n",
        "\n",
        "    print(\"\\n[GPT-2 Evaluation]\")\n",
        "    gpt2_test_loader = DataLoader(\n",
        "        test_dataset_raw,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=XNLIDataset.collate_fn\n",
        "    )\n",
        "\n",
        "    gpt2_acc, gpt2_preds, _ = evaluate_model_nli(\n",
        "        finetuned_model, tokenizer, gpt2_test_loader,\n",
        "        model_type=\"gpt2\", device=DEVICE\n",
        "    )\n",
        "    results['gpt2'][lang] = gpt2_acc\n",
        "\n",
        "    # ===== Qwen =====\n",
        "    print(\"\\n[Qwen Evaluation]\")\n",
        "    qwen_test_dataset = XNLIDataset(\n",
        "        split=\"test\",\n",
        "        lang=lang,\n",
        "        tokenizer=qwen_tokenizer,\n",
        "        subset=TEST_SUBSET\n",
        "    )\n",
        "\n",
        "    qwen_test_loader = DataLoader(\n",
        "        qwen_test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=XNLIDataset.collate_fn\n",
        "    )\n",
        "\n",
        "    qwen_acc, qwen_preds, _ = evaluate_model_nli(\n",
        "        qwen_finetuned, qwen_tokenizer, qwen_test_loader,\n",
        "        model_type=\"qwen\", device=DEVICE\n",
        "    )\n",
        "    results['qwen'][lang] = qwen_acc\n",
        "\n",
        "    print(f\"\\n{lang}: GPT-2 = {gpt2_acc*100:.1f}% | Qwen = {qwen_acc*100:.1f}%\")"
      ],
      "metadata": {
        "id": "hB_rFaiJlpsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f1e80a-0eb1-4e63-ff0a-3788d3cef87b"
      },
      "id": "hB_rFaiJlpsK",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Testing on en\n",
            "============================================================\n",
            "Dataset initialized: split='test', lang='en', total=5010, subset=1, subset_count=5010\n",
            "\n",
            "[GPT-2 Evaluation]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating gpt2: 100%|██████████| 5010/5010 [01:12<00:00, 68.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2 Evaluation accuracy: 78.82%\n",
            "\n",
            "[Qwen Evaluation]\n",
            "Dataset initialized: split='test', lang='en', total=5010, subset=1, subset_count=5010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating qwen: 100%|██████████| 5010/5010 [02:43<00:00, 30.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWEN Evaluation accuracy: 84.21%\n",
            "\n",
            "en: GPT-2 = 78.8% | Qwen = 84.2%\n",
            "\n",
            "============================================================\n",
            "Testing on th\n",
            "============================================================\n",
            "Dataset initialized: split='test', lang='th', total=5010, subset=1, subset_count=5010\n",
            "\n",
            "[GPT-2 Evaluation]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating gpt2: 100%|██████████| 5010/5010 [01:37<00:00, 51.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2 Evaluation accuracy: 34.71%\n",
            "\n",
            "[Qwen Evaluation]\n",
            "Dataset initialized: split='test', lang='th', total=5010, subset=1, subset_count=5010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating qwen: 100%|██████████| 5010/5010 [02:44<00:00, 30.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWEN Evaluation accuracy: 63.39%\n",
            "\n",
            "th: GPT-2 = 34.7% | Qwen = 63.4%\n",
            "\n",
            "============================================================\n",
            "Testing on ar\n",
            "============================================================\n",
            "Dataset initialized: split='test', lang='ar', total=5010, subset=1, subset_count=5010\n",
            "\n",
            "[GPT-2 Evaluation]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating gpt2: 100%|██████████| 5010/5010 [01:22<00:00, 60.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2 Evaluation accuracy: 35.89%\n",
            "\n",
            "[Qwen Evaluation]\n",
            "Dataset initialized: split='test', lang='ar', total=5010, subset=1, subset_count=5010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating qwen: 100%|██████████| 5010/5010 [02:43<00:00, 30.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWEN Evaluation accuracy: 67.66%\n",
            "\n",
            "ar: GPT-2 = 35.9% | Qwen = 67.7%\n",
            "\n",
            "============================================================\n",
            "Testing on de\n",
            "============================================================\n",
            "Dataset initialized: split='test', lang='de', total=5010, subset=1, subset_count=5010\n",
            "\n",
            "[GPT-2 Evaluation]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating gpt2: 100%|██████████| 5010/5010 [01:16<00:00, 65.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2 Evaluation accuracy: 40.76%\n",
            "\n",
            "[Qwen Evaluation]\n",
            "Dataset initialized: split='test', lang='de', total=5010, subset=1, subset_count=5010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating qwen: 100%|██████████| 5010/5010 [02:43<00:00, 30.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWEN Evaluation accuracy: 71.14%\n",
            "\n",
            "de: GPT-2 = 40.8% | Qwen = 71.1%\n",
            "\n",
            "============================================================\n",
            "Testing on zh\n",
            "============================================================\n",
            "Dataset initialized: split='test', lang='zh', total=5010, subset=1, subset_count=5010\n",
            "\n",
            "[GPT-2 Evaluation]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating gpt2: 100%|██████████| 5010/5010 [01:17<00:00, 64.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2 Evaluation accuracy: 37.62%\n",
            "\n",
            "[Qwen Evaluation]\n",
            "Dataset initialized: split='test', lang='zh', total=5010, subset=1, subset_count=5010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating qwen: 100%|██████████| 5010/5010 [02:43<00:00, 30.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QWEN Evaluation accuracy: 71.54%\n",
            "\n",
            "zh: GPT-2 = 37.6% | Qwen = 71.5%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97219667bb9846d68df0451427c6beca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c94e5271748a46eda10e107ce42e916c",
              "IPY_MODEL_70a53f778ab04ee1b7236d93786c65bf",
              "IPY_MODEL_27388a6abcf44262b7b3e945f2d6534c"
            ],
            "layout": "IPY_MODEL_ec68dc4fd0fd4841860d7f31c2979872"
          }
        },
        "c94e5271748a46eda10e107ce42e916c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fabb95a87b2e4ebca96bf8498a485441",
            "placeholder": "​",
            "style": "IPY_MODEL_4058baf34b0b429eb5f0dce78becda41",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "70a53f778ab04ee1b7236d93786c65bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d5fd812213455ea3a720c060ade310",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81e4146cce5a4aff9591af846df9217f",
            "value": 26
          }
        },
        "27388a6abcf44262b7b3e945f2d6534c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ea86727678451cacaa664b97db08a8",
            "placeholder": "​",
            "style": "IPY_MODEL_695857dcf9ca4c8a9550111d97ada250",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.40kB/s]"
          }
        },
        "ec68dc4fd0fd4841860d7f31c2979872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fabb95a87b2e4ebca96bf8498a485441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4058baf34b0b429eb5f0dce78becda41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30d5fd812213455ea3a720c060ade310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e4146cce5a4aff9591af846df9217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59ea86727678451cacaa664b97db08a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "695857dcf9ca4c8a9550111d97ada250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0173166a0b85412db9f6c8d5a12ad45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ce935d2c2a646d9869ede8a53d9a0b2",
              "IPY_MODEL_61c5e5fdbed947e384c775756ba7969d",
              "IPY_MODEL_4fe76772b0ff4cfcb5494e2a6aeb44f0"
            ],
            "layout": "IPY_MODEL_87ee0a80977c40859cd87fa774a9043f"
          }
        },
        "9ce935d2c2a646d9869ede8a53d9a0b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb4bb743d264c1b8d5d0859af520ba1",
            "placeholder": "​",
            "style": "IPY_MODEL_f2cd2a25acb6427dbbdaab68dd5ebf4e",
            "value": "vocab.json: 100%"
          }
        },
        "61c5e5fdbed947e384c775756ba7969d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e8b6aa514d45429a13341d3faf174f",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37e7e6da19ad4abcbd4394c13c9111ad",
            "value": 1042301
          }
        },
        "4fe76772b0ff4cfcb5494e2a6aeb44f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54221a4bc855477a98d1dcc61f81a76e",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f2807e599e4cf085d4b4ef8c77e0a8",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.71MB/s]"
          }
        },
        "87ee0a80977c40859cd87fa774a9043f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb4bb743d264c1b8d5d0859af520ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2cd2a25acb6427dbbdaab68dd5ebf4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44e8b6aa514d45429a13341d3faf174f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e7e6da19ad4abcbd4394c13c9111ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54221a4bc855477a98d1dcc61f81a76e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f2807e599e4cf085d4b4ef8c77e0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5a3a31f803a481399970c8e557dac20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bb9140b6c4d468ea609eed8b2452565",
              "IPY_MODEL_9ef1ac88c1a5444d871c79fc48e5759b",
              "IPY_MODEL_bce9ce866dfe40d2b6764aba1a5689b1"
            ],
            "layout": "IPY_MODEL_02be77a380b24aaeb7df8e9667231a22"
          }
        },
        "2bb9140b6c4d468ea609eed8b2452565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776ffe626f6a4280a4a23e89dc474193",
            "placeholder": "​",
            "style": "IPY_MODEL_216962566e0f4795aad21b8397bd2539",
            "value": "merges.txt: 100%"
          }
        },
        "9ef1ac88c1a5444d871c79fc48e5759b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db5b58687434bb68de7acad3478cdf4",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74f446d177a644208b725b59f085a3fa",
            "value": 456318
          }
        },
        "bce9ce866dfe40d2b6764aba1a5689b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff4e258a755c429c939d4927e1fbbf2b",
            "placeholder": "​",
            "style": "IPY_MODEL_347ee5f33ccb4d708f258a06d9a17df6",
            "value": " 456k/456k [00:00&lt;00:00, 24.5MB/s]"
          }
        },
        "02be77a380b24aaeb7df8e9667231a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "776ffe626f6a4280a4a23e89dc474193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216962566e0f4795aad21b8397bd2539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1db5b58687434bb68de7acad3478cdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f446d177a644208b725b59f085a3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff4e258a755c429c939d4927e1fbbf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347ee5f33ccb4d708f258a06d9a17df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd67dcfb363b4dd3b376897817ef3485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38cedb1b3a78445086b5a80f0fc6f080",
              "IPY_MODEL_4ffce14b5b264e749f83227f1cb5f508",
              "IPY_MODEL_000a1228d4e74672835301761252c2ec"
            ],
            "layout": "IPY_MODEL_dc9f669b66524368a7917757adb605cc"
          }
        },
        "38cedb1b3a78445086b5a80f0fc6f080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25744974de2d4f13a98e11371a87b568",
            "placeholder": "​",
            "style": "IPY_MODEL_58383d31d54040748cb0d56e229a0ccf",
            "value": "tokenizer.json: 100%"
          }
        },
        "4ffce14b5b264e749f83227f1cb5f508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59276f586f21496fadd259345b4c85bd",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53019c62e7e64f48b5b487b1eec8e67a",
            "value": 1355256
          }
        },
        "000a1228d4e74672835301761252c2ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1f360ee61e04530b627f06357e7679b",
            "placeholder": "​",
            "style": "IPY_MODEL_bb2e120f73464dfba5fb1c60bc6a516c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.08MB/s]"
          }
        },
        "dc9f669b66524368a7917757adb605cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25744974de2d4f13a98e11371a87b568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58383d31d54040748cb0d56e229a0ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59276f586f21496fadd259345b4c85bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53019c62e7e64f48b5b487b1eec8e67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1f360ee61e04530b627f06357e7679b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2e120f73464dfba5fb1c60bc6a516c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b281671ab51b4ecfaa46a6748d0a345c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ddf01ea2287428f9d79b06a0addce3d",
              "IPY_MODEL_cd4b82b64787432f8fec09c35fc56439",
              "IPY_MODEL_1c444bd674884991b0965e35768e79dd"
            ],
            "layout": "IPY_MODEL_a13b1344e7fa43bd91297fea2f2ca060"
          }
        },
        "5ddf01ea2287428f9d79b06a0addce3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86015e175ff94427954673c82800eeb3",
            "placeholder": "​",
            "style": "IPY_MODEL_dd7767ac609643bd84f40c044a2895ca",
            "value": "config.json: 100%"
          }
        },
        "cd4b82b64787432f8fec09c35fc56439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a8747ed682544c7943e3ebca7788fee",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90c117aabc324d378d43be91c926c90b",
            "value": 665
          }
        },
        "1c444bd674884991b0965e35768e79dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f68c36329894c5fbc3ce091bc87fd42",
            "placeholder": "​",
            "style": "IPY_MODEL_59450c1d1fec44d58f1e62a42e54e881",
            "value": " 665/665 [00:00&lt;00:00, 89.5kB/s]"
          }
        },
        "a13b1344e7fa43bd91297fea2f2ca060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86015e175ff94427954673c82800eeb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd7767ac609643bd84f40c044a2895ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a8747ed682544c7943e3ebca7788fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c117aabc324d378d43be91c926c90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f68c36329894c5fbc3ce091bc87fd42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59450c1d1fec44d58f1e62a42e54e881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3be0d1760935451fa0e37a3c52210e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe068f7d689b4bd7bcac7c6904ee5a2e",
              "IPY_MODEL_d8cedb21736540cda767580b658d1119",
              "IPY_MODEL_1b124309fc394f55bdb50f5248bee783"
            ],
            "layout": "IPY_MODEL_cb8338892bf34dfdbfe5a0dad18f45b3"
          }
        },
        "fe068f7d689b4bd7bcac7c6904ee5a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddd9c3cf77d147ad8d2192d456af2b94",
            "placeholder": "​",
            "style": "IPY_MODEL_a37a4b690b814a31a5dac0a102e815e5",
            "value": "model.safetensors: 100%"
          }
        },
        "d8cedb21736540cda767580b658d1119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_487e4181ee574d8680ce2e59af91a45d",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8dc271d772244a28f5e90113514b606",
            "value": 548105171
          }
        },
        "1b124309fc394f55bdb50f5248bee783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd26cf0155148faacbd342e61666996",
            "placeholder": "​",
            "style": "IPY_MODEL_409a6fed972449d38ae9ca20161cd937",
            "value": " 548M/548M [00:02&lt;00:00, 493MB/s]"
          }
        },
        "cb8338892bf34dfdbfe5a0dad18f45b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd9c3cf77d147ad8d2192d456af2b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37a4b690b814a31a5dac0a102e815e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "487e4181ee574d8680ce2e59af91a45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8dc271d772244a28f5e90113514b606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebd26cf0155148faacbd342e61666996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409a6fed972449d38ae9ca20161cd937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1707dbad9a1642019ff860fdc2d70c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_948641abfecc48aea2dfce48a4da4b83",
              "IPY_MODEL_f0fe9a75259a45eea55e99cb218efce6",
              "IPY_MODEL_f81bd26973774bbfb0e286be3ca066a5"
            ],
            "layout": "IPY_MODEL_00a9a4c943ba4d838de40b7d9b7df2ed"
          }
        },
        "948641abfecc48aea2dfce48a4da4b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bc4ebff1856456999818b4a63a528a4",
            "placeholder": "​",
            "style": "IPY_MODEL_7be844d1a19343fe99c5885d2979ebe4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f0fe9a75259a45eea55e99cb218efce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d4b2f81462a4e8a806338e3e4388714",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e18c289616794bfd9b5950fd63d2213f",
            "value": 26
          }
        },
        "f81bd26973774bbfb0e286be3ca066a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ec2f4ebab7454c8b9c7c21c0005eb5",
            "placeholder": "​",
            "style": "IPY_MODEL_cfd178e263ae4cf294991e89b1c9401e",
            "value": " 26.0/26.0 [00:00&lt;00:00, 3.20kB/s]"
          }
        },
        "00a9a4c943ba4d838de40b7d9b7df2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc4ebff1856456999818b4a63a528a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7be844d1a19343fe99c5885d2979ebe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d4b2f81462a4e8a806338e3e4388714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18c289616794bfd9b5950fd63d2213f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76ec2f4ebab7454c8b9c7c21c0005eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfd178e263ae4cf294991e89b1c9401e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e65d21760c0f40aabcc649ae36e19114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c77642a6e1604ca1b4a1d0c98e68de55",
              "IPY_MODEL_4959063a16a34123aa38677ec420f3eb",
              "IPY_MODEL_fb1ba33627af4e3d812f3d6053b626d5"
            ],
            "layout": "IPY_MODEL_a75bf1e5f5e348bcb75c4df4d15fed33"
          }
        },
        "c77642a6e1604ca1b4a1d0c98e68de55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f29b46393ed4490bbf9b0c54d83d932e",
            "placeholder": "​",
            "style": "IPY_MODEL_3e90fc3e8a564ed2a6f32341acc5571a",
            "value": "vocab.json: 100%"
          }
        },
        "4959063a16a34123aa38677ec420f3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3be41b98dadb4b5bbf989450cff1d429",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5646402e508649679a4773cf31bde1a6",
            "value": 1042301
          }
        },
        "fb1ba33627af4e3d812f3d6053b626d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcba96b6edef4cadb2a5747d87df3b03",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c450b4a90740e2a5169abe90e631b6",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 2.42MB/s]"
          }
        },
        "a75bf1e5f5e348bcb75c4df4d15fed33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29b46393ed4490bbf9b0c54d83d932e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e90fc3e8a564ed2a6f32341acc5571a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3be41b98dadb4b5bbf989450cff1d429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5646402e508649679a4773cf31bde1a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcba96b6edef4cadb2a5747d87df3b03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c450b4a90740e2a5169abe90e631b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb64d90a3d9b4358a59b29470452b052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a4ec23e55444f96ac7a6a65ae45ec04",
              "IPY_MODEL_ef08f17d7906468ab6a8e6b426dde75f",
              "IPY_MODEL_788c157999d54e45b3af81fe96a40aef"
            ],
            "layout": "IPY_MODEL_5e10a0135b6a4b709058193dba2487e4"
          }
        },
        "0a4ec23e55444f96ac7a6a65ae45ec04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acea27534bc64c7eb2c63e92449ffbcd",
            "placeholder": "​",
            "style": "IPY_MODEL_9deef9eecedd4265b67db928e116aa44",
            "value": "merges.txt: 100%"
          }
        },
        "ef08f17d7906468ab6a8e6b426dde75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_458c9290076a47a992be69f329479db2",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62d5ef40d4df47f9b7d1236bd639c514",
            "value": 456318
          }
        },
        "788c157999d54e45b3af81fe96a40aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0015f752c39546a38da9b3f0b6457c7f",
            "placeholder": "​",
            "style": "IPY_MODEL_a9142ee2da5248b588f5c24a2aab2d21",
            "value": " 456k/456k [00:00&lt;00:00, 1.09MB/s]"
          }
        },
        "5e10a0135b6a4b709058193dba2487e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acea27534bc64c7eb2c63e92449ffbcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9deef9eecedd4265b67db928e116aa44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "458c9290076a47a992be69f329479db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d5ef40d4df47f9b7d1236bd639c514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0015f752c39546a38da9b3f0b6457c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9142ee2da5248b588f5c24a2aab2d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a9f02b258e44ffba29e71761a2bcbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8e6064b69bf44edbe036e5fbf36db1e",
              "IPY_MODEL_74b8afab89fe42c4b74473afa385e12b",
              "IPY_MODEL_d17336c6ab384470bb32e9728c120f6f"
            ],
            "layout": "IPY_MODEL_48fa42556c3a4086918ed5b9d3562431"
          }
        },
        "e8e6064b69bf44edbe036e5fbf36db1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6054543afd2d4e469aee2aef79e2bb20",
            "placeholder": "​",
            "style": "IPY_MODEL_1d9ed0a92ed94d91a3299e36d7c91b50",
            "value": "tokenizer.json: 100%"
          }
        },
        "74b8afab89fe42c4b74473afa385e12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4899dffbd084fcd867b541d372208d5",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc7674391d5f4cadb40966b5af00ac0e",
            "value": 1355256
          }
        },
        "d17336c6ab384470bb32e9728c120f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c424441f2fb46daabd8bd0b0fa2fdb6",
            "placeholder": "​",
            "style": "IPY_MODEL_1fbaf4cdd10441778ce70379a2ff93c7",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 57.2MB/s]"
          }
        },
        "48fa42556c3a4086918ed5b9d3562431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6054543afd2d4e469aee2aef79e2bb20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9ed0a92ed94d91a3299e36d7c91b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4899dffbd084fcd867b541d372208d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7674391d5f4cadb40966b5af00ac0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c424441f2fb46daabd8bd0b0fa2fdb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fbaf4cdd10441778ce70379a2ff93c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f75b362ae71c40878560cd6680df360e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0f34124c2c44c19b67807208d9258dd",
              "IPY_MODEL_fdedf39acca9457c94aafb9fe54b5443",
              "IPY_MODEL_71c20fb6869f4c64971807b8d8441a98"
            ],
            "layout": "IPY_MODEL_bf9a8081e5364835be18b106591f5c0c"
          }
        },
        "e0f34124c2c44c19b67807208d9258dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35259415f24e4282b68545eac15b59a8",
            "placeholder": "​",
            "style": "IPY_MODEL_0e29feff2c6a4eefacc3ecc44b20a611",
            "value": "config.json: 100%"
          }
        },
        "fdedf39acca9457c94aafb9fe54b5443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a000d52bc9ad4e499a0269f307e2f742",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea09837f2982452dafe88d95d4d12864",
            "value": 665
          }
        },
        "71c20fb6869f4c64971807b8d8441a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5df1e0d550445c7a43076f1476a0597",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1e1427b5fb4c2697b64857682fadff",
            "value": " 665/665 [00:00&lt;00:00, 52.0kB/s]"
          }
        },
        "bf9a8081e5364835be18b106591f5c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35259415f24e4282b68545eac15b59a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e29feff2c6a4eefacc3ecc44b20a611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a000d52bc9ad4e499a0269f307e2f742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea09837f2982452dafe88d95d4d12864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5df1e0d550445c7a43076f1476a0597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1e1427b5fb4c2697b64857682fadff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfe6d0f49c064530a4df0996dcfefe15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de9186a7de394c369afe117fb916967e",
              "IPY_MODEL_8602d16e999441da95ca2e7521536c2a",
              "IPY_MODEL_7ed7a136fb0a4aee88a30d18ddfe3382"
            ],
            "layout": "IPY_MODEL_15c86c9dba3541f2ac37ff2967d40f9d"
          }
        },
        "de9186a7de394c369afe117fb916967e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f45d53af6ec04d9cb9ecb83820baf331",
            "placeholder": "​",
            "style": "IPY_MODEL_97369070a5c94d9c99dc18f759061231",
            "value": "model.safetensors: 100%"
          }
        },
        "8602d16e999441da95ca2e7521536c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_465be133b03841cbbc398f64adbbe6c6",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75686760234a4b48b1c43d13523e8d84",
            "value": 548105171
          }
        },
        "7ed7a136fb0a4aee88a30d18ddfe3382": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d62e4ffa5b4ea8b43fccc0c1c1297d",
            "placeholder": "​",
            "style": "IPY_MODEL_dd888136c49c47cfbae8e599026c69ea",
            "value": " 548M/548M [00:03&lt;00:00, 287MB/s]"
          }
        },
        "15c86c9dba3541f2ac37ff2967d40f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45d53af6ec04d9cb9ecb83820baf331": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97369070a5c94d9c99dc18f759061231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "465be133b03841cbbc398f64adbbe6c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75686760234a4b48b1c43d13523e8d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25d62e4ffa5b4ea8b43fccc0c1c1297d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd888136c49c47cfbae8e599026c69ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}